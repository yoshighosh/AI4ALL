{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Berkeley AI4ALL 2019 - Disaster Relief.ipynb","version":"0.3.2","provenance":[{"file_id":"1GYQlxJ2DGTM5zY9d_7lHCSauGKp1KoKO","timestamp":1565889314299},{"file_id":"1lIpUJW3EN_klPfUWDN-rNK-aCGFaPjzu","timestamp":1565849000551}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"r_Xl4tym_lSS","colab_type":"text"},"source":["# Disaster Relief\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bb/Defense.gov_photo_essay_100124-D-0000G-001.jpg\" alt=\"A U.S. Navy sailor carries a Haitian boy off a helicopter at Terminal Varreux, Haiti, Jan. 23, 2010, as the boy's mother follows behind them. The child received treatment aboard one of the U.S. Navy ships serving as a hospital in Port-au-Prince harbor, Haiti and he was later discharged. U.S. military personnel are providing aid and support to earthquake victims in Haiti.\" width=\"400\"/>\n","\n","During a disaster, proper communication between those who need aid and those who can provide it is crucial. Disaster responders need to sort through thousands of messages to identify who needs help, what they need, and where they are. \n","\n","In this project, we will use **supervised learning** to predict whether a message is related to aid or not. This means our task is **binary classification** (i.e. related or not), and we will use methods from natural language processing (NLP) to handle our data. NLP is a branch of AI that combines computer science and linguistics to process and understand language. \n","\n","**Q:** What are some examples of NLP in your everyday life? \n","\n","There is a lot in this notebook! So ask lots of questions. :)\n","\n","### Colaboratory\n","\n","You are currently using a Colaboratory notebook, which runs Jupyter notebooks. There are text cells and code cells, and you'll be writing mostly in code cells, though feel free to double click and edit text cells to write answers to the questions we've sprinkled throughout (marked **Q**). \n","\n","A key idea is to make sure you run cells in order, and double check that you've run previous cells before running a current cell. When you declare a variable or function in a cell, you need to run it so the notebook \"remembers\" it for use in future cells. \n","\n","To run a cell, press Shift->Enter or click on the play button in the top left corner of the cell. \n","\n","Feel free to go to Tools -> Preferences -> Miscellaneous to adjust some fun settings. \n","\n","Make sure you use a **GPU**! Go to Runtime -> Change runtime type -> set Hardware accelator to GPU. "]},{"cell_type":"code","metadata":{"id":"J461sDp1mTdJ","colab_type":"code","colab":{}},"source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_selection import chi2\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.manifold import TSNE\n","import csv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","from collections import Counter\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords \n","from scipy.spatial.distance import cosine\n","import random\n","import seaborn as sns\n","from matplotlib.lines import Line2D\n","import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CH9kFPnZFbOS","colab_type":"code","outputId":"f8c0b931-c364-4cf1-8ee1-5b6004b2cddd","executionInfo":{"status":"ok","timestamp":1565965981640,"user_tz":420,"elapsed":1837,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","import os\n","os.environ['PYTHONHASHSEED'] = '0'"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2t_Rb9TLxKO7","colab_type":"text"},"source":["Go [here](https://drive.google.com/drive/folders/1Us07XmdDjnysYIl5IuE9PLfDVDZ_qkuh?usp=sharing) to download the following files. \n","\n","*  `disaster_test.csv`\n","*  `disaster_validation.csv`\n","*  `disaster_train.csv`\n","*  `glove.twitter.27B.100d.txt`\n","\n","Place the files you will need in a folder called \"Berkeley AI4ALL\" in your Google Drive.\n","\n","Then run the following cell and select the Google account that has the folder with files you just created. \n","\n"]},{"cell_type":"code","metadata":{"id":"1tGX0epKUQkF","colab_type":"code","outputId":"9661886c-ecec-4319-90de-78cbd796be2b","executionInfo":{"status":"ok","timestamp":1565967563022,"user_tz":420,"elapsed":1583204,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path = '/content/drive/My Drive/Berkeley AI4ALL/'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1tUFIJFqmO8A","colab_type":"text"},"source":["\n","## Data \n","\n","We are using a dataset involving events such as an earthquake in Haiti in 2010, an earthquake in Chile in 2010, floods in Pakistan in 2010, super-storm Sandy in the U.S.A. in 2012, and news articles spanning 100s of different disasters. Each message is labeled by human annotators as aid related or not. \n","\n","This dataset is already separated into training, validation, and test sets, so we will load in these data sets below. \n","\n","**Q:** Why is it good practice to separate our data like this?\n","\n","**Q:** Should we look at our test set while we develop our models? "]},{"cell_type":"code","metadata":{"id":"mJja9n7T_gP0","colab_type":"code","outputId":"c8ba768e-19fc-40b8-fdfc-bcab129cfca0","executionInfo":{"status":"ok","timestamp":1565967566268,"user_tz":420,"elapsed":1586435,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Load data\n","def get_data(infile_path): \n","    '''\n","    @inputs: \n","        - infile_path: string representing the path of the input file\n","        - vectorizer: our CountVectorizer which turns strings of\n","        text into vectors containing the counts of words\n","    @outputs: \n","        - X: numpy array of word counts\n","        - y: numpy array of labels that are 0 or 1\n","    '''\n","    X = []\n","    y = []\n","    c = 0\n","    with open(infile_path, 'r') as infile: \n","        reader = csv.DictReader(infile)\n","        for row in reader: \n","            X.append(row['message'])\n","            y.append(int(row['aid_related']))\n","    return np.array(X, dtype=object), np.array(y)\n","  \n","X_train, y_train = get_data(path + 'disaster_training.csv')\n","X_val, y_val = get_data(path + 'disaster_validation.csv')\n","X_test, y_test = get_data(path + 'disaster_test.csv')\n","\n","data = pd.DataFrame({\"Headlines\": X_train, \"label\": y_train})\n","\n","data"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Headlines</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Weather update - a cold front from Cuba that c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Is the Hurricane over or is it not over</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>says: west side of Haiti, rest of the country ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Information about the National Palace-</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Storm at sacred heart of jesus</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Please, we need tents and water. We are in Sil...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>I would like to receive the messages, thank you</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>There's nothing to eat and water, we starving ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>I am in Petionville. I need more information r...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>I am in Thomassin number 32, in the area named...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Let's do it together, need food in Delma 75, i...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>More information on the 4636 number in order f...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>A Comitee in Delmas 19, Rue ( street ) Janvier...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>We need food and water in Klecin 12. We are dy...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>I don't understand how to use this thing 4636.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>I would like to know if the earthquake is over...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>I would like to know if one of the radio ginen...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>I'm in Laplaine, I am a victim</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>There's a lack of water in Moleya, please info...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Those people who live at Sibert need food they...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>I want to say hello, my message is to let you ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>Can you tell me about this service</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>How can we get water and food in Fontamara 43 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>We need help. Carrefour has been forgotten com...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>Good evening, Radio one please. I would like i...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>We have a lot of problem at Delma 75 Avenue Al...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>I'm here, I didn't find the person that I need...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>People have been sleeping outdoors in a field ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>We want you to know that Carrefour need help, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>I would like to get help at Cote Plage in Carr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>21016</th>\n","      <td>One of the major difficulties confronting heal...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21017</th>\n","      <td>Commodities yet to be resourced to avoid a pip...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21018</th>\n","      <td>Day 12: We head north to the edge of the Guera...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21019</th>\n","      <td>Museveni, quoted by AP, criticised foreign inv...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21020</th>\n","      <td>Some families have been temporarily sheltered ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21021</th>\n","      <td>The World Health Organization and Norway gathe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21022</th>\n","      <td>The ability to pick dengue from influenza is c...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21023</th>\n","      <td>A Federation chartered ship arrived from Lae w...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21024</th>\n","      <td>The result is that in Aceh province many prefa...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21025</th>\n","      <td>Otherwise, the risk is families fleeing again ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21026</th>\n","      <td>A United Nations team from the Electoral Assis...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21027</th>\n","      <td>It was decided that all vehicle movement from ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21028</th>\n","      <td>The tendency to link deforestation with large ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21029</th>\n","      <td>Polio is a viral disease that attacks the nerv...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21030</th>\n","      <td>The new constitution declares that 'Somalia is...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21031</th>\n","      <td>We're providing clean water to people who woul...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21032</th>\n","      <td>Relief items include towels, sanitary napkins,...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21033</th>\n","      <td>In Aceh's Meulaboh town the UN refugee agency ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21034</th>\n","      <td>The closure has stopped 169 inbound flights an...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21035</th>\n","      <td>BANGKOK, 24 January 2012 (NNT) - Prime Ministe...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21036</th>\n","      <td>Cadmium, a metallic element widely used in bat...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21037</th>\n","      <td>Epidemic surveillance: National Institute of C...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21038</th>\n","      <td>2.1 Due to sporadic skirmishes in eastern D.R....</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21039</th>\n","      <td>No other army had gone to greater lengths to a...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21040</th>\n","      <td>The delivery was made in conjunction with the ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21041</th>\n","      <td>The training demonstrated how to enhance micro...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21042</th>\n","      <td>A suitable candidate has been selected and OCH...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21043</th>\n","      <td>Proshika, operating in Cox's Bazar municipalit...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>21044</th>\n","      <td>Some 2,000 women protesting against the conduc...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>21045</th>\n","      <td>A radical shift in thinking came about as a re...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>21046 rows × 2 columns</p>\n","</div>"],"text/plain":["                                               Headlines  label\n","0      Weather update - a cold front from Cuba that c...      0\n","1                Is the Hurricane over or is it not over      1\n","2      says: west side of Haiti, rest of the country ...      0\n","3                 Information about the National Palace-      0\n","4                         Storm at sacred heart of jesus      0\n","5      Please, we need tents and water. We are in Sil...      1\n","6        I would like to receive the messages, thank you      0\n","7      There's nothing to eat and water, we starving ...      1\n","8      I am in Petionville. I need more information r...      0\n","9      I am in Thomassin number 32, in the area named...      1\n","10     Let's do it together, need food in Delma 75, i...      1\n","11     More information on the 4636 number in order f...      0\n","12     A Comitee in Delmas 19, Rue ( street ) Janvier...      1\n","13     We need food and water in Klecin 12. We are dy...      1\n","14        I don't understand how to use this thing 4636.      0\n","15     I would like to know if the earthquake is over...      0\n","16     I would like to know if one of the radio ginen...      0\n","17                        I'm in Laplaine, I am a victim      1\n","18     There's a lack of water in Moleya, please info...      1\n","19     Those people who live at Sibert need food they...      1\n","20     I want to say hello, my message is to let you ...      0\n","21                    Can you tell me about this service      0\n","22     How can we get water and food in Fontamara 43 ...      1\n","23     We need help. Carrefour has been forgotten com...      1\n","24     Good evening, Radio one please. I would like i...      0\n","25     We have a lot of problem at Delma 75 Avenue Al...      1\n","26     I'm here, I didn't find the person that I need...      0\n","27     People have been sleeping outdoors in a field ...      0\n","28     We want you to know that Carrefour need help, ...      1\n","29     I would like to get help at Cote Plage in Carr...      1\n","...                                                  ...    ...\n","21016  One of the major difficulties confronting heal...      1\n","21017  Commodities yet to be resourced to avoid a pip...      0\n","21018  Day 12: We head north to the edge of the Guera...      1\n","21019  Museveni, quoted by AP, criticised foreign inv...      0\n","21020  Some families have been temporarily sheltered ...      1\n","21021  The World Health Organization and Norway gathe...      1\n","21022  The ability to pick dengue from influenza is c...      1\n","21023  A Federation chartered ship arrived from Lae w...      1\n","21024  The result is that in Aceh province many prefa...      1\n","21025  Otherwise, the risk is families fleeing again ...      0\n","21026  A United Nations team from the Electoral Assis...      0\n","21027  It was decided that all vehicle movement from ...      1\n","21028  The tendency to link deforestation with large ...      0\n","21029  Polio is a viral disease that attacks the nerv...      0\n","21030  The new constitution declares that 'Somalia is...      0\n","21031  We're providing clean water to people who woul...      1\n","21032  Relief items include towels, sanitary napkins,...      1\n","21033  In Aceh's Meulaboh town the UN refugee agency ...      1\n","21034  The closure has stopped 169 inbound flights an...      0\n","21035  BANGKOK, 24 January 2012 (NNT) - Prime Ministe...      1\n","21036  Cadmium, a metallic element widely used in bat...      0\n","21037  Epidemic surveillance: National Institute of C...      1\n","21038  2.1 Due to sporadic skirmishes in eastern D.R....      1\n","21039  No other army had gone to greater lengths to a...      0\n","21040  The delivery was made in conjunction with the ...      0\n","21041  The training demonstrated how to enhance micro...      0\n","21042  A suitable candidate has been selected and OCH...      0\n","21043  Proshika, operating in Cox's Bazar municipalit...      0\n","21044  Some 2,000 women protesting against the conduc...      1\n","21045  A radical shift in thinking came about as a re...      0\n","\n","[21046 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"A5nTixV7_MFZ","colab_type":"text"},"source":["A good starting point to any machine learning project is **data exploration**, so let's explore our data! \n","\n","Our datasets are NumPy arrays. NumPy is a Python library that has handy functions for working with vectors and matrices. \n","\n","You can get the size of a matrix with `shape`, which returns a tuple. A tuple is like a list, but you cannot add more items or remove items from it. \n","\n","**Q:** Is Python 0-indexed or 1-indexed? "]},{"cell_type":"code","metadata":{"id":"Dbj_IU7m_hkQ","colab_type":"code","outputId":"172d88fe-5a6e-4d2d-9a6f-d4093d14a3f2","executionInfo":{"status":"ok","timestamp":1565967566269,"user_tz":420,"elapsed":1586421,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["# Example of using shape\n","Z = np.array([[1, 2, 3],[4, 5, 6]])\n","print(\"We created an array Z that looks like this: \", Z)\n","print(\"The dimensions of Z are %s.\" % (Z.shape,))\n","print(\"The first dimension of Z is %d.\" % Z.shape[0])\n","print(\"The second dimension of Z is %d.\" % Z.shape[1])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["We created an array Z that looks like this:  [[1 2 3]\n"," [4 5 6]]\n","The dimensions of Z are (2, 3).\n","The first dimension of Z is 2.\n","The second dimension of Z is 3.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Gd_vxWavXnxd","colab_type":"code","outputId":"5ecfa82e-6eab-49be-953c-a31f9d88c399","executionInfo":{"status":"ok","timestamp":1565967566269,"user_tz":420,"elapsed":1586409,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Count the total number of data samples in the \n","# train, validation, and test data sets\n","### YOUR CODE HERE ###\n","\n","print(\"There are {} samples in the training data\".format(X_train.shape[0]))\n","print(\"There are {} samples in the validation data\".format(X_val.shape[0]))\n","print(\"There are {} samples in the test data\".format(X_test.shape[0]))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["There are 21046 samples in the training data\n","There are 2573 samples in the validation data\n","There are 2629 samples in the test data\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GL6iDFt4yOKL","colab_type":"text"},"source":["NumPy can allow you to easily count the number of times a value appears in an array. "]},{"cell_type":"code","metadata":{"id":"ThJVc7s7yX7-","colab_type":"code","outputId":"c9184961-c144-4395-ce3d-188ebf6cd0a8","executionInfo":{"status":"ok","timestamp":1565967566270,"user_tz":420,"elapsed":1586399,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Example of using count_nonzero to count something\n","Z = np.array([1, 2, 2, 3, 3, 3, 4, 4, 4, 4])\n","print(Z==3)\n","np.count_nonzero(Z == 3)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[False False False  True  True  True False False False False]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"Ok-MAsT7YbJc","colab_type":"code","outputId":"05baad30-f9f3-443a-cd1a-c5d737bfa1f7","executionInfo":{"status":"ok","timestamp":1565967566271,"user_tz":420,"elapsed":1586386,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# What percent of labels in our training set are aid related? \n","# What percent are not? \n","# HINT: the labels (y) associated with each input (x) will contain this information\n","### YOUR CODE HERE ###\n","\n","percentage = np.count_nonzero(y_train == 1)/y_train.shape[0]\n","print(\"The percentage of aid related labels is {:.2f}%\".format(percentage*100))\n","print(\"The percentage of non aid related labels is {:.2f}%\".format((1-percentage)*100))"],"execution_count":8,"outputs":[{"output_type":"stream","text":["The percentage of aid related labels is 41.27%\n","The percentage of non aid related labels is 58.73%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ynpm6qjszu5u","colab_type":"text"},"source":["It is helpful to know how many words are usually in each message in our dataset. Use `word_tokenize` to calculate this. For example, `word_tokenize('I eat cheese.')` would result in `['I', 'eat', 'cheese', '.']`.\n","\n","**Q:** Do messages tend to be very short (<100 words) or very long (>100 words)?"]},{"cell_type":"code","metadata":{"id":"wFqVHzrhWujW","colab_type":"code","outputId":"1c024ee9-b2f1-4210-da54-a8e4925f8cd0","executionInfo":{"status":"ok","timestamp":1565967571451,"user_tz":420,"elapsed":1591552,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":371}},"source":["# How long are the messages in our training set? \n","message_lengths = []\n","# Use a for loop over X_train to fill up message_lengths\n","### YOUR CODE BEGINS HERE ###\n","for msg in X_train:\n","  message_lengths.append(len(word_tokenize(msg)))\n","### YOUR CODE ENDS HERE ###\n","\n","# Visualize the message lengths using a histogram\n","plt.hist(message_lengths, bins=50, log=True)\n","plt.xlabel(\"length of message\")\n","plt.ylabel(\"log frequency\")\n","plt.show()\n","\n","# Compare short versus long messages\n","print(\"Number of short messages: %s\" \n","      % np.count_nonzero(np.array(message_lengths) < 100))\n","print(\"Number of long messages: %s\" \n","      % np.count_nonzero(np.array(message_lengths) > 100))\n","\n","\n","for i in message_lengths:\n","  if i > 1750:\n","    print(X_train[message_lengths.index(i)])\n","    "],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Number of short messages: 20942\n","Number of long messages: 102\n","The weather forecast indicates that rains should go on until at least late December. The severe drought parching east Africa has left 10 million facing hunger and the scope of one of the world's worst unfolding humanitarian disasters conjured up memories of Ethiopia's devastating 1984 famine. Seismologists agree that Padang will face more earthquakes in future, and warn that a much larger quake with far greater destructive force is inevitable in the region. The flash floods that followed torrential monsoonal rains in north-west Pakistan between 28 and 30 July have caused great loss of life and wide-spread damage to infrastructure, livestock and property in more than 100 villages. Lesotho and Swaziland would also experience scattered rains, he noted. But while floodwaters have subsided in some areas, there has been fresh flooding in the north of the state and more heavy rainfall forecast elsewhere. Approximately 1.9 million people have been affected in the past week by heavy torrential monsoon rains which flooded 195 blocks in 14 districts of the State of West Bengal. Separately, the West Java administration has said it plans to once more dredge the Citarum river to reduce the mass of sedimentation that contributes to the area's annual floods. With the help of the American Red Cross, Mr. Fernando and his family are using a compost bin to help remove from the streets household garbage that blocks drains and causes flooding. Continuing, he said the United Nations and its partners were also pursuing ways to promote water harvesting and implement modernized irrigation facilities so communities in the region were not totally dependent on rainwater to keep crops alive during dry spells. It may be mentioned here that long range forecasts of the Indian southwest monsoon rainfall are generated by many other national and global centres which employ different prediction techniques. The availability of feed from grain and crop residues has also fallen sharply due to the drop in agricultural production, especially in rainfed areas. Last year, hundreds of people died in several avalanches following record snowfalls. The northern and eastern parts of the country received less rain in the past northeastern monsoon and expect inter monsoonal showers these days. The initial assessments indicated that nearly 15,000 people had been affected - already double the estimates made on Tuesday - with over 8,000 left without shelter and two people dead. The southern African nation of Mozambique has once again been inundated by flood waters and hurricane force winds. Furthermore, the most recent cyclone to hit the country, tropical storm Manou, killed more than 70 people in May, severed roads and bridges and caused extensive damage to agricultural land. A blanket of acrid smog covered the sweltering capital itself, worsening the woes of Muscovites gasping in Russia's hottest weather since record-keeping began around 1880. Where localised flooding has forced the evacuation of whole communities, the authorities have moved residents to safer areas. This rapid-response shipment includes critically needed supplies to care for the thousands injured in Saturday's disaster: first-aid supplies, materials for making casts to set broken arms and legs, walkers, canes, crutches, warm weather clothing for hospital patients and hygiene kits. Further bad weather is predicted, with the government issuing a cyclone warning for Karachi and other coastal communities in the coming days. Two people were killed when a tree uprooted by the wind fell on them at a village in Chandpur district 170 km (106 miles) southeast of the capital Dhaka on Sunday. 4-7 February: Torrential rain coupled with seasonal rainfall leads to some of the worst flooding in Mozambique in more than half a century. The pledges made, in order of magnitude in terms of per annum commitments, included the following:. The cyclone and subsequent flooding in Baluchistan have killed 25 people, while 12 people were killed on Thursday in a separate deluge in the northwest of the country. More funds are needed to provide medicines, food and shelter. In the wake of the system temperatures are forecast to fall far below zero, with accompanying wind chill factor. By Himadri Ahsan, IFRC The monsoon depression over the northeast Bay of Bengal and adjoining Bangladesh coast intensified into a cyclonic storm named 'Komen' on Wednesday, 29 July, threatening to cause further downpours in regions that are already affected by the recent flash floods and deadly landslides. Freaky winter storms have plagued southern China since mid-January, leading to widespread traffic jams, structural collapse, blackouts and crop loss in 21 provincial-level regions. Skin diseases due to poor hygiene or biting insects are widespread and reported to be a major problem in Dadu district. Roiling floods triggered by unusually heavy monsoon rain have scoured Pakistan's Indus river basin, killing more than 1,600 people, forcing 2 million from their homes and disrupting the lives of about 14 million people, or 8 percent of the population. JAKARTA, Indonesia (Reuters) - Indonesia's neighbors on Friday sent in firefighters to train Indonesian crews battling bushfires on Sumatra island as the haze-making blazes spread. It was the second severe hail storm to hit the province this month. The lack of sanitation - particularly latrines - poses a more serious as residents of all three camps have no choice but to defecate in bushland or on the beach. Today the children of Qungkunchack village are taking classes in the open air in near zero degree temperatures. The Meteorological Department has forecast rainfall would decrease from Thursday to Saturday, but return in the North and Northeast on Sunday and Monday. Tens of thousands were killed when the world's strongest earthquake in 40 years unleashed flash floods and giant waves on South and Southeast Asia. To keep their herd alive, she corralled the animals into tight pens while her husband Batdorj trudged into the darkness and blowing snow to look for strays. For a second time in less than a month, DPR Korea has been affected by floods triggered by torrential rainfalls produced by Typhoon Rusa. While on the visit of the village after the storm, the Prime Minister Edward Lowasa called on the people to build stronger structures for safer housing of their families and plant more trees that would act as wind breakers during stormy weather. A State of Emergency was declared today (21 August) by the authorities in Hunan Province while the water level of Dongting Lake, the second largest fresh water lake in China, continues to rise (Dongting Lake acts as a giant overflow for the flood prone Yangtze River). The agency said the intermittent downpours of the last several days would be followed by heavy rains and perhaps even tornadoes. National experts in infrastructure damage assessment (six weeks). Luoyang city experienced six days of continuous heavy rain, with the average daily rainfall reaching 100 millimeters (four inches), the report said. The KRCS has been distributing mosquito nets in a bid to prevent malaria epidemics. Having its origin in the Chitral Gol National Park, the stream was seen carrying with it a large number of deodar logs. In addition, it is extremely prone to natural disasters; such as floods, drought, earthquakes, volcanic eruptions, snowfall, typhoons and cyclones which have important social and economic consequences. BEIJING, Aug 5, 2006 (AFP) - Typhoon Prapiroon killed at least 31 people and left 14 others missing after crashing ashore in southern China, state media reported Saturday, announcing the latest casualty figures. Reports indicate at least 40 people were killed and more than 180 others injured following the earthquake that struck south-east Iran deep beneath the surface with tremors felt across Pakistan, India and the Gulf States. To date, authorities have listed 190 Fukushima workers as victims of radiation sickness, the most acute form of radiation exposure that results in damage to multiple organ systems, skin burns, and usually a slow deterioration and death. MADRID, March 18 (Reuters) - International humanitarian groups are finding pockets of suffering in northern Japan, but say most victims of the earthquake, tsunami, and snow blizzards are keeping warm and getting food, water and medical attention. Papua New Guinea is on the Pacific volcanic belt known as the ''Ring of Fire,'' and has more than a dozen active volcanoes. KYANGIN  -  Due to the rising tides of Ayeyawady River from erosion, 13 families from four villages in Yelekyun village in Kyangin Township were evacuated to safer locations on 3 September. MUMBAI, July 5, 2006 (AFP) - Large tracts of India's western financial hub of Mumbai were under water Wednesday as the weather bureau warned further heavy rains were on the way and the death toll from the monsoon deluge rose to nine. The disaster has been compounded by a severe winter storm. TOKYO, Dec 28, 2004 (Xinhua via COMTEX) -- Japan Tuesday sent a Maritime Self- Defense Force convoy, including a helicopter, to waters off Thailand to help search for missing people following Sunday's earthquake and subsequent tsunamis in the Southeast and South Asian region. Only spotty light rain is expected during the period. Half of Bibi's tent floor was soaked in rain water, making the plunging temperatures nearly unbearable at night, she said. Recent snow flurries and fog have prevented the planned airdrops from taking place as frequently as had been hoped, and the increasingly muddy roads make truck convoys hazardous at times. On 17 August, approximately 25 veterinarians, sponsored by FAO, arrived in Badakhshan to commence the summer vaccination campaign. In Indonesia, CWS has focused on four main activities: emergency distribution of food and non-food items for over 12,000 internally displaced people in Banda Aceh and Aceh Besar; a mobile clinic medical team and a psychosocial mental health team serving displaced people; and water supply and sanitation in Meulaboh. The national seismological network said the quake jolted the juncture between Sichuan's Suining City and Tongnan County of Chongqing Municipality at 5:36 a.m. Weather officials said islands in the Bay of Bengal were gripped by high tides caused by monsoon clouds, and warned all fishing boats to return to their bases. They failed to evacuate after the second powerful quake struck and got trapped in the hotel rubble, said the staffer, who gave his name as Harun.\n","While the focus is to save lives and fight diseases, it is also important to address underlying risks, such as solid and liquid waste, industrial chemicals, sewage treatment and the salinization of drinking water. WHO and UNICEF have reported that their efforts to combat polio appear to have resulted in its eradication in the northern, western and eastern provinces. Six people drowned overnight in Assam state as they tried to escape gushing floodwaters in bamboo rafts, state relief and rehabilitation minister Bhumidhar Barman said. We think that evaluation of the situation in the IDP barracks could be a next step to implement because there seems to be reduced focus on this problem -- we already visited one IDP barracks camp and found many cases of scabies, some cutaneaous mycosis and skin allergy. Family consumption habits have changed, and in many cases been reduced to two meals per day. \"There were already poor water and sanitation facilities and now there is a high risk of water and foodborne diseases,\" says Dr Vickneswaran Sabaratnam, WHO's Consultant Epidemiologist who recently visited Abe Barak. \"The government had given [over $215,490, or 20,000,000 Kenyan shillings] for the purchase of biometric registration equipment in order for us to be able to vet and register the refugees,\" said Ojode. A high population growth rate, dwindling farm size, unjust patterns of land tenure, inefficient farming techniques, deforestation, and degraded soils all contribute to chronic disaster. The water at the creek is not sufficient to cater for drinking and cooking purposes at the care center. Prices are expected to decrease further when the rainfed sorghum harvest enters the market. As the tsunami hit in the Maha (wet) season, paddy was the hardest hit mono-crop, next to fruits and vegetables grown in homegardens. As 50-75% of piped water is lost through leaking pipes, lack of taps, misuse etc., UNICEF will launch an awareness campaign through the mass media. I know that my mum couldn't survive after two months,' said Maung Htwe, 18, as he cooked rice for the rest of the family in the shack they cobbled together from storm debris. Angolan authorities have found the presumed wreck of a twin- engine Cessna aircraft that disappeared two weeks ago with its two crewmen, the director of the national civil aviation authority told Lusa on Friday. Up to 2,400 people are provided with water at 20 x 3,000 litre static water tanks placed in strategic positions along national roads. However, tetanus boosters may be indicated for previously vaccinated people who sustain open wounds or for other injured people depending on their tetanus immunization history. 44-gallon drums for latrine construction. Post-disaster communicable illness is expected to rise as a result of the high degree of displacement. Reports from the Red Cross mobile medical units (MMU) in different districts in Assam also show an increase in the incidence of gastrointestinal ailments, diarrhoea, fever, anaemia and vitamin deficiency.Typically they carry medical supplies, food rations, electrical generating equipment, relief workers, including doctors and sanitation experts, machinery, and shelter building materials. At the most flooded camp, Ifo, refugees had to carry what remained of their meagre belongings through the water to temporary shelters on higher ground 20 km (12 miles) away. Two of the smugglers were found to have tortured the detainees with an electrical cable and iron chain.\". He said all camp families were being issued with further equipment, including additional corrugated galvanised iron sheeting, or winter tents, blankets and quilts. The rains will also affect the population at large, making roads impassable due to mudslides and flooding, and cutting off some areas from humanitarian assistance and basic services. Irrigation systems are needed to grow more food and fight poverty and hunger, but they can serve as breeding sites for mosquitoes that transmit malaria. Through weekly coordination meetings, chaired by the Commissioner for Disaster Preparedness, Relief and Rehabilitation, the authorities aim to ensure a coherent, effective and well-targeted emergency relief operation, extending into the subsequent rehabilitation phase. He plans to use the money from UNDP's Social Safety Net programme to buy a welding machine so that in addition to his regular work as a mechanic-driver, he can fix gates, coal pots and other metal goods. Several pastoral tribes occupy the southern part of the region -- routinely hit by drought -- and rely on land for animal grazing. Among these, are four infrastructure grants to help lay the foundation and preparation for the renovation of feeder roads and the rehabilitation of a man-made lake for irrigation purposes. A priority need is to ensure clean water and adequate sanitary conditions. For more information, or to read the complete speeches made by the women peace leaders to Security Council Members, visit www.unifem.undp.org. OCHA is ready to serve as a channel for unearmarked contributions towards the activities of the Appeal, which will then be allocated by the UNDMT in accordance with agreed priorities. IOM plans to help some 40,000 people displaced by the quake to make informed decisions to voluntarily return home between April 1st and October 31st. Some 500,000 people were evacuated because of the storm and 28 people died from landslides, a capsized boat and illness. These rains disrupted harvesting patterns for all crops; accentuated seed drop in teff; slowed the rate of desiccation of later sown grains prior to threshing; increased spoilage in stacks of harvested cereals; caused some germination in standing crops of wheat and sorghum; and increased the likelihood of fungal attacks in both standing and stored grains, particularly pulses. 3 - 132 kV abcb and 1 220 kV SF6 circuit breakers had failed porcelain insulators. Project Outputs: To rehabilitate eight primary schools, including classrooms, teacher housing and bathroom facilities, to government standards. * to build up household coping mechanisms * to rebuild destroyed community assets * to strengthen the capacity and structure of the Orissa State Red Cross Branch. Of this, international assistance will be required for 2 million tons in the form of rice loans, grants, concessionary imports and targeted food aid. The project will also respond to basic requests by affected farmers such as gypsum and organic fertilizers for soil reclamation, and seedlings for coconut, oil palm and fruit trees. Nitin Bilolikar, medical superintendent of Civil Hospital, Pune, concurred that groundwater contamination was a serious worry. Different cluster partners (UNICEF, IFRC, Canadian DART Team, DFID, WHO, Oxfam, Pakistan Hikers Association, etc.) have delivered the following material: 20,000 jerry cans and 5 tanks (11 cubic meters) for 60,000 people have been delivered to Muzaffarabad, in addition to two mobile treatment plants, 80 latrine slabs and plastic sheeting for latrine construction for 1,600 people. The IRC will work with local groups to implement projects that include drilling and improving wells, constructing and repairing irrigation systems and distributing farming supplies. The analysis in the Science paper, based on early data from Mexico, also appears to indicate that this influenza A(H1N1) outbreak is somewhat different from seasonal influenza outbreaks. A shortage of rainfall means that more water evaporates from drought affected areas. Twenty per cent of those who develop chronic liver disease go into more advanced diseases like cancer. \"First we hydrate intravenously or with oral rehydration salts, then we administer antibiotics and parasitic drugs.\". Human and financial resource mobilization continues to be sought from WHO's partners, UN agencies, and other stakeholders. UNDP has arranged the preparation of 200,000 Urea Molasses Blocks (UMB) to supplement the poor grazing and crop residue feeding of 30,000 breeding sheep and goats in the hard hit areas of Balochistan province. Meanwhile the construction of four units of prefabs (for a health clinic) in Gle Putoh, Lamno is ongoing. The foundation provided each family with a compost bin and taught the women how to store all the biodegradable material in the bin. BEIJING, Jul 17, 2006 (Xinhua via COMTEX) -- At least 14 people were confirmed dead when a swelling river flooded a colliery in central China's Hunan Province Saturday, bringing the country's death toll of the tropical storm Bilis to 170. These crowded living conditions highlight the ongoing medical emergency in the capital. As for the reconstruction of homes (with solar-powered lights and latrines with biogas digesters) and the provision of livelihood opportunities, this project seeks to replace the broken track that has derailed the victims' lives and to empower them in moving forward.\". MRCS volunteer groups are now providing chlorine at water points in some parts of the city where people are using open wells or boreholes which have become polluted with surface runoff. From a spacious, well-stocked, well-supplied kitchen with a paid employee to cramped quarters without cupboards and just two single-burner gas stoves, the couple is starting all over again. From rainwater catchment systems to micro-dams, we don't keep digging wells in areas where they keep failing - we find a water solution to fit. Tonkolili, one of the most economically productive parts of Sierra Leone, has seen a relatively small proportion of the country's Ebola infections but is experiencing a continued spread which threatens its farming and mining industries. A maternal mortality rate of 880 per 100,000 live births reflects this critical state of affairs. On January 10, the Ministry of Health (MOH) reported new cases of diarrheas, ARIs and viral fevers but said their numbers continue to be within expected range with no upward trend. Vice Minister of Public Security Huang Ming, who arrived in the quake-hit area on Sunday, ordered the police to ensure the safety of roads leading to and from the affected area and strengthen traffic diversion programs throughout the area. Since the beginning of October, FAO through its implementing partner OISCA, has distributed nearly 100 tonnes of rice seeds, over 230 tonnes of NPK fertilizers, and approximately 400 tonnes of urea fertilizer in Bantul and Klaten to more than 130 farmer groups (more than 10,000 faming household beneficiaries). Mercy Corps visited Masohi village of in Central Maluku district to socialize some guidelines on economic empowerment programme to local cooperating partners. Pungent smell from open sewer, clogged drains, filthy water and broken roads have all together made it virtually impossible for a quick return,\" he said.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qPQXLfP-fOI1","colab_type":"text"},"source":["Now, we will look at some example messages in each label. \n","\n","An index is the location of an element in a list or array. The following cell uses `np.where` to find indices where `y_train` is 0 or 1, randomly samples 5 indices, and prints out the messages in `X_train` at those indices.  "]},{"cell_type":"code","metadata":{"id":"GVFwnwohZ9--","colab_type":"code","outputId":"09f4f99a-6f3a-44d7-9b6c-31717f75fde2","executionInfo":{"status":"ok","timestamp":1565967571451,"user_tz":420,"elapsed":1591541,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":326}},"source":["# Feel free to rerun this cell multiple times to look at more messages\n","print(\"Messages related to aid:\\n\")\n","for idx in random.sample(list(np.where(y_train == 1)[0]), 5): \n","  print(y_train[idx], X_train[idx])\n","print(\"\\n-------------------\\n\")\n","print(\"Messages not related to aid:\\n\")\n","for idx in random.sample(list(np.where(y_train == 0)[0]), 5): \n","  print(y_train[idx], X_train[idx])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Messages related to aid:\n","\n","1 Tarpaulin sheets will also be distributed to cover temporary shelters and make them fully waterproofed.\n","1 *By Katarina Hije* BAMAKO, 30 April 2015 (IRIN) - The last few years in Mali have been busy: an independence declaration, a coup, a mutiny, a northern takeover by Islamist groups, a French military intervention, a hostage crisis, a guerrilla campaign, a preliminary peace deal, and finally, in February, a ceasefire.\n","1 All donated items will be delivered to Myanmar via the Friendship Bridge.\n","1 Dubai (dpa) - A major telethon hosted by the Dubai-based Al-Arabiya channel in association with Saudi television has raised 32 million dollars for the victims of the massive earthquake in Pakistan, the Saudi Press Agency reported Sunday.\n","1 The Garisa-Dadab road in Kenya is closed to traffic due to high incidents of banditry, but for Garisa based operations, all convoys must have a prior security clearance and accompanied by one escort vehicle.\n","\n","-------------------\n","\n","Messages not related to aid:\n","\n","0 Dangerous toxic waste: A senior pesticides expert has disclosed that 1,500 tons of expired toxic pesticides are stored in 256 stations across Ethiopia.\n","0 \"At one point, I was thinking to abandon my volunteering.\"\n","0 In Fontamara 35, 43 people are drinking water from a pipe. They don't know how many microbes are in this water. Please forward this message for (sentence cut off) \n","0 I would like to know if tonight we will have an aftershock.\n","0 The Provincial Government is developing a scheme to provide the building materials for one of these houses, together with 10% of the cost of building, to eligible families.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"wOWwMUTIVaf-","colab_type":"text"},"source":["## Baseline\n","\n","As a reminder, our goal is to use the examples in the training data to create a model that will predict whether or not a given message is related to aid.\n","\n","It is good practice to establish a baseline to compare our models against. An example of a simple baseline for this task would be a classifier that predicts the majority class. \n","\n","**Q**: Pretend you are living in a drought. Would this baseline be a good classifier for predicting rain each day? \n","\n","We saw above that the most common class in our dataset are messages that are not aid related. So, this baseline would predict a label of 0 for every message. \n","\n","To implement this, we will use `np.zeros(n)`, where `n` is the length of the resulting zero vector. "]},{"cell_type":"code","metadata":{"id":"1FZAYaQZT_59","colab_type":"code","outputId":"d10edc9e-d4fd-439a-d73d-6d5e2b311f90","executionInfo":{"status":"ok","timestamp":1565967571452,"user_tz":420,"elapsed":1591532,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Example of np.zeros()\n","print(np.zeros(5))\n","print(np.zeros(10))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[0. 0. 0. 0. 0.]\n","[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4lFhmTDLVZ3n","colab_type":"code","colab":{}},"source":["# Assign y_train_pred and y_val_pred to your predicted y labels \n","# for the train and validation data sets, respectively\n","### YOUR CODE BEGINS HERE ###\n","y_train_pred = np.zeros(y_train.shape[0])\n","y_val_pred = np.zeros(y_val.shape[0])\n","### YOUR CODE ENDS HERE ###"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-a7SdbvyzbrE","colab_type":"text"},"source":["## Evaluation\n","\n","To judge how good a model is, we have two **evaluation** metrics: accuracy and F1. \n","\n","**Accuracy** is the number of correct predictions performed by our model, divided by the number of total predictions. "]},{"cell_type":"code","metadata":{"id":"6_6ES2Dcza0v","colab_type":"code","colab":{}},"source":["def calculate_accuracy(y_true, y_pred): \n","  # Calculate accuracy of the baseline using a for loop\n","  # HINT: accuracy = correct/total\n","  ### YOUR CODE BEGINS HERE ###\n","  correct = 0\n","  index = 0\n","  for i in y_true:\n","    if y_true[index] == y_pred[index]:\n","      correct += 1\n","    index += 1\n","  return correct/y_true.shape[0]\n","      \n","  ### YOUR CODE ENDS HERE ###"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpyagvLq2E0Z","colab_type":"code","outputId":"3ddb8d11-4feb-4482-e728-ca38a3312136","executionInfo":{"status":"ok","timestamp":1565967571454,"user_tz":420,"elapsed":1591515,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Calculate and print the accuracy of this baseline\n","# on the train and val data sets \n","# using the function you wrote above\n","### YOUR CODE BEGINS HERE ###\n","print(\"The accuracy is {:.2f}%\".format(calculate_accuracy(y_train, y_train_pred)*100))\n","print(\"The accuracy is {:.2f}%\".format(calculate_accuracy(y_val, y_val_pred)*100))\n","### YOUR CODE ENDS HERE ###"],"execution_count":14,"outputs":[{"output_type":"stream","text":["The accuracy is 58.73%\n","The accuracy is 59.27%\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"WH0JfFJtJnF5","colab_type":"text"},"source":["Note: A lot of calculations on arrays and matrices that can be done in a for loop can be **vectorized** using NumPy. Vectorization is faster and used all the time by AI researchers. "]},{"cell_type":"code","metadata":{"id":"x-UhK1st2ZMO","colab_type":"code","outputId":"b99922fa-f559-4c0f-e371-47c6b190a368","executionInfo":{"status":"ok","timestamp":1565967571455,"user_tz":420,"elapsed":1591503,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Calculate and print the accuracy of the baseline\n","# on the train and val sets using NumPy functions \n","print(\"Training accuracy:\", np.count_nonzero(y_train==y_train_pred)/y_train.shape[0])\n","print(\"Validation accuracy:\", np.count_nonzero(y_val==y_val_pred)/y_val.shape[0])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Training accuracy: 0.5873325097405683\n","Validation accuracy: 0.5926933540614069\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NtssBzcC2dE4","colab_type":"text"},"source":["If a dataset is unbalanced, which means there are different numbers of examples for each class, it is often useful to report the **F1 score**. \n","\n","First let's review the different kinds of errors and correct predictions we can make. \n","\n","|   \t|   Actual: Yes\t| Actual: No   \t|  \n","|---\t|---\t|---\t|\n","| **Predicted: Yes**  \t|  True Positive (TP) \t|  False Positive (FP) | \n","| **Predicted: No**  \t| False Negative (FN)\t| True Negative (TN)\t| \n","\n","These values help us compute precision and recall. \n","\n","$$Precision = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$$\n","\n","$$ Recall = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$$ \n","\n","For our task, we have the following \"plain English\" definitions: \n","- True Positive: a tweet is related to aid, and we predict it is. \n","- False Positive: a tweet isn't related to aid, and we predict it is. \n","- False Negative: a tweet is related to aid, and we predict it isn't. \n","- True Negative: a tweet is not related to aid, and we predict it isn't. \n","- Precision: Of all tweets we predicted as related to aid, how many are actually aid-related? \n","- Recall: Of all tweets labeled as related to aid, how many were we able to detect? \n","\n","The F1 score combines precision and recall, and is defined as follows: \n","\n","$$F1 = \\frac{2(Precision)(Recall)}{Precision + Recall}$$\n","\n","For our baseline, the F1 score is undefined (!) because the number of true positives and false positives is zero and precision cannot be calculated. "]},{"cell_type":"code","metadata":{"id":"_Q11b8fjG69D","colab_type":"code","colab":{}},"source":["def calculate_F1(y_true, y_pred): \n","  '''\n","  A function for calculating F1\n","  Start by computing TP, FP, and FN, \n","  then precision and recall. \n","  @inputs: \n","    - y_pred: numpy array of predicted labels\n","    - y_true: numpy array of actual labels\n","  '''\n","  true_positives = 0\n","  false_positives = 0\n","  false_negatives = 0\n","  ### YOUR CODE BEGINS HERE ###\n","  for i in range(y_true.shape[0]):\n","    if y_true[i] == 1:\n","      if y_pred[i] == 1:\n","        true_positives += 1\n","      elif y_pred[i] == 0:\n","        false_negatives += 1\n","    elif y_true[i] == 0:\n","      if y_pred[i] == 1:\n","        false_positives += 1\n","  \n","  precision = true_positives / (true_positives + false_positives)\n","  recall = true_positives / (true_positives + false_negatives)\n","  \n","  f1 = (2*precision*recall)/(precision+recall)\n","  ### YOUR CODE ENDS HERE ###\n","  return f1\n","\n","def test_calculate_F1(): \n","  '''\n","  Compares our implementation with sklearn's.\n","  '''\n","  y_pred = np.array([1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1])\n","  y_true = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n","  assert calculate_F1(y_true, y_pred) ==  f1_score(y_true, y_pred)\n","  \n","  y_pred = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1])\n","  y_true = np.array([1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1])\n","  assert calculate_F1(y_true, y_pred) ==  f1_score(y_true, y_pred)\n","  \n","# If this runs without errors then you're all good!\n","test_calculate_F1()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9YQ3oS1aWabf","colab_type":"text"},"source":["## Logistic Regression"]},{"cell_type":"markdown","metadata":{"id":"KLsVoBRa1rim","colab_type":"text"},"source":["Now let's move onto some more sophisticated models. \n","\n","As you may have learned earlier this week, logistic regression is a type of classifier that can handle categorical outputs. (Linear regression, on the other hand, can be used to predict continuous outputs, e.g. float numbers.)\n","\n","For example, you could use logistic regression to predict whether it will rain or not tomorrow, but you would use linear regression to predict the actual amount of rain in inches. \n","\n","Our prediction task is binary, so there are only two categories of outcomes. So, we can use logistic regression for our task. \n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/640px-Logistic-curve.svg.png?1565220409285\" alt=\"Standard Logistic Function\" width=\"400\"/>\n","\n","(The plot above is of a standard logistic function, or a \"generic\" version of the function used in logistic regression. You don't need to understand it completely, but knowing it makes a curvy shape that allows the top half to be categorized as one class and another half to be the other class is enough. )\n","\n","Logistic regression predicts the following:\n","\n","$$\\hat{y} = \\frac{1}{1 + e^{-(w_1x + w_2)}},$$\n","\n","where $w_1$ and $w_2$ are weights (which we need to figure out), $x$ is our input, and $\\hat{y}$ is the prediction. \n","\n","Our input is each message, but for a computer to \"read\" it, we need to transform the message of words into numbers. \n","\n","One way to do this is to represent each message as a vector of word counts. We'll use a `CountVectorizer` to do this. After vectorizing, each row of the input matrix corresponds to a message, each column corresponds to a word, and each entry corresponds to the number of times that message contained that word. "]},{"cell_type":"code","metadata":{"id":"JJqQtnMRdBbH","colab_type":"code","outputId":"c3ee72e7-146c-4207-b424-7b481acb1b4d","executionInfo":{"status":"ok","timestamp":1565967571455,"user_tz":420,"elapsed":1591482,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["# Example of CountVectorizer on a toy dataset\n","Z = ['I like cats', 'I like dogs', 'Dogs like cats'] \n","vectorizer = CountVectorizer(max_features=3)\n","vectorizer.fit(Z)\n","Z_matrix = vectorizer.transform(Z)\n","print(vectorizer.get_feature_names())\n","print(Z_matrix.todense())"],"execution_count":17,"outputs":[{"output_type":"stream","text":["['cats', 'dogs', 'like']\n","[[1 0 1]\n"," [0 1 1]\n"," [1 1 1]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jz5ZiKl0shrE","colab_type":"text"},"source":["Now, time to write up some code! \n","\n","Note that we limit the number of words in our vectorizer to the top 2000 most common ones so that # of features < # of training examples. It is good practice to have fewer features than examples due to the [curse of dimensionality](https://medium.com/diogo-menezes-borges/give-me-the-antidote-for-the-curse-of-dimensionality-b14bce4bf4d2). \n","\n","In the code below, you will \\\\\n","(a) fit a vectorizer to the training data, \\\\\n","(b) use that vectorizer to transform the training and validation data, \\\\\n","(c) fit a logistic regression model to the transformed training data, \\\\\n","(d) make predictions using the logistic regression model, \\\\\n","(e) and check the accuracy of your model on the training and validation data.\n","\n","Note that a `LogisticRegression` object has the function `fit(X, y)` to train the model, and the function `predict(X)` to output the predicted labels. You will use these functions in the code below."]},{"cell_type":"code","metadata":{"id":"Wj4mL6ZzWbg4","colab_type":"code","colab":{}},"source":["def run_log_reg(): \n","    print(\"Getting data...\")\n","    # Use the get_data function to get \n","    # X_train, y_train, X_val, and y_val\n","    ### YOUR CODE BEGINS HERE ###\n","    X_train, y_train = get_data(path + 'disaster_training.csv')\n","    X_val, y_val = get_data(path + 'disaster_validation.csv')\n","    X_test, y_test = get_data(path + 'disaster_test.csv')\n","    ### YOUR CODE ENDS HERE ###\n","    \n","    print(\"Vectorizing...\")\n","    # Initialize CountVectorizer with max_features=2000\n","    # Fit vectorizer onto X_train\n","    # Transform X_train and X_val using that vectorizer\n","    \n","    ### YOUR CODE BEGINS HERE ###\n","    vectorizer = CountVectorizer(max_features = 1850)\n","    vectorizer.fit(X_train)\n","    X_train = vectorizer.transform(X_train)\n","    X_val = vectorizer.transform(X_val)\n","    ### YOUR CODE ENDS HERE ###\n","    \n","    print(\"Size of X_train and y_train after vectorizing:\", \n","          X_train.shape, y_train.shape)\n","    print(\"Size of X_val and y_val after vectorizing:\", \n","          X_val.shape, y_val.shape) \n","    print(\"Fitting model...\")\n","    model1 = LogisticRegression(random_state=0, solver='liblinear')\n","    # Fit LogisticRegression model on X_train and y_train\n","    # Predict on X_train and X_val to get y_train_pred and y_val_pred\n","    ### YOUR CODE BEGINS HERE ###\n","    model1.fit(X_train, y_train)\n","    y_train_pred = model1.predict(X_train)\n","    y_val_pred = model1.predict(X_val)\n","    ### YOUR CODE ENDS HERE ###\n","    print(\"Training accuracy:\", accuracy_score(y_train, y_train_pred))\n","    print(\"Training F1:\", f1_score(y_train, y_train_pred))\n","    print(\"Validation accuracy:\", accuracy_score(y_val, y_val_pred)) \n","    print(\"Validation F1:\", f1_score(y_val, y_val_pred)) \n","    \n","    return model1, vectorizer.get_feature_names()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qB8GHXEdwYpn","colab_type":"code","outputId":"20f91faa-62c5-42a7-d1db-5df180ffb00f","executionInfo":{"status":"ok","timestamp":1565967572940,"user_tz":420,"elapsed":1592953,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":170}},"source":["model1, vocab = run_log_reg()"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Getting data...\n","Vectorizing...\n","Size of X_train and y_train after vectorizing: (21046, 1850) (21046,)\n","Size of X_val and y_val after vectorizing: (2573, 1850) (2573,)\n","Fitting model...\n","Training accuracy: 0.8164971966169343\n","Training F1: 0.7631546669937447\n","Validation accuracy: 0.7668091721725612\n","Validation F1: 0.696969696969697\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3l4F74i5nVNz","colab_type":"text"},"source":["**Q**: Did this logistic regression model perform better or worse than our baseline model?\n","\n","One of the useful aspects of logistic regression is you can look at the coefficients, or learned weights, to understand the effect that the given feature (or word) had on the overall prediction. \n","\n","**Q**: What do you notice about the words that distinguish the two classes of messages? "]},{"cell_type":"code","metadata":{"id":"0Q61mGn3hddu","colab_type":"code","outputId":"3bcebdf0-f739-4cab-c4df-fba3b3b2e7dd","executionInfo":{"status":"ok","timestamp":1565967572942,"user_tz":420,"elapsed":1592944,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":748}},"source":["# Look at coefficients! \n","coefficients = model1.coef_[0]\n","indices = np.argsort(coefficients) # sort low->high\n","# Most negatively weighted\n","print(\"Not related to aid\")\n","for i in indices[:20]:\n","  print(vocab[i], coefficients[i])\n","print()\n","# Most positively weighted\n","print(\"Related to aid\")\n","for i in indices[-20:]: \n","  print(vocab[i], coefficients[i])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Not related to aid\n","incomplete -2.064746941520863\n","showers -1.812309441644281\n","stations -1.703213273377864\n","southwest -1.5650078293419165\n","job -1.498148121127859\n","2013 -1.470235341749554\n","milk -1.4084807031981599\n","cans -1.3967699726400513\n","passport -1.3154936970214808\n","enable -1.2934244739622685\n","visa -1.2886612508241662\n","met -1.2863970925448396\n","preparation -1.2848980385506572\n","jesus -1.1897530148689177\n","indonesian -1.1875767140029738\n","spent -1.1745079319474887\n","prices -1.1680654311314302\n","religious -1.1668296668189426\n","traditional -1.1663135550704822\n","availability -1.1620274392778835\n","\n","Related to aid\n","victims 1.4721226818562687\n","death 1.4960229585746436\n","missing 1.5101214856749174\n","hunger 1.5304499296861755\n","dying 1.5474682465116443\n","killing 1.5726370362989706\n","targeted 1.5791428031557617\n","donation 1.6093926275878843\n","tents 1.6254686000097756\n","shelter 1.6470200300750812\n","donate 1.6742473498500372\n","survivors 1.6824817737401738\n","dead 1.7018421783820519\n","tent 1.703748699058197\n","terrorist 1.7791864826808852\n","trapped 1.8240378432935702\n","shelters 1.8264108603956277\n","deaths 2.2192500351350803\n","hungry 2.222020640661485\n","starving 2.2802116754285855\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8cwPHV38Wdah","colab_type":"text"},"source":["## Neural Networks\n","\n","Now, time to play around with even bigger models! \n","\n","**Deep learning** is one of the most popular areas of AI right now. A neural network trains on a dataset and updates its weights using backpropagation. You can think of backpropagation as a downstream of error messages, telling the neural network to make small adjustments to perform better in the next iteration. After training, a neural network uses its weights to predict on new data. \n","\n","You can combine multiple neurons together into layers, where the outputs of one layer feed into the next one. \n","\n","To implement neural networks we will use a Python library called Keras. \n","\n","I tend to think of Keras as a box of legos, and the different size legos and colors correspond to different kinds of neural network layers we can put together. "]},{"cell_type":"code","metadata":{"id":"snzvQAM0afoP","colab_type":"code","outputId":"a620bab5-2c63-4dcc-ee80-0a46f1d0d3e7","executionInfo":{"status":"ok","timestamp":1565967575646,"user_tz":420,"elapsed":1595638,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":224}},"source":["# import\n","from keras import backend as K\n","import tensorflow as tf\n","K.tensorflow_backend._get_available_gpus()"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n","WARNING: Logging before flag parsing goes to stderr.\n","W0816 14:59:34.214594 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","W0816 14:59:34.216333 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","W0816 14:59:34.217515 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0816 14:59:35.495695 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["['/job:localhost/replica:0/task:0/device:GPU:0']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"qUmLynz1Weci","colab_type":"code","colab":{}},"source":["# more imports\n","from keras.preprocessing.text import one_hot, Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense, LSTM, Flatten, CuDNNLSTM, Dropout, BatchNormalization\n","from keras.layers.embeddings import Embedding\n","from keras.regularizers import l2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LpkyGnX_GO9M","colab_type":"text"},"source":["Before we create any model, we need to wrangle our message data into the correct input format. \n","\n","First, we need to map each word to some unique integer value. This will allow us to represent each message as a vector of these integers. \n","\n","Below is an example using a toy dataset. "]},{"cell_type":"code","metadata":{"id":"altoCjvmMV7s","colab_type":"code","outputId":"f9da8a31-168b-4ce3-a585-dda27f625ba0","executionInfo":{"status":"ok","timestamp":1565967575649,"user_tz":420,"elapsed":1595628,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# Example of using a Keras Tokenizer \n","Z = ['I like cats and dogs', 'I like dogs', 'Dogs like cats'] \n","tokenizer = Tokenizer()\n","\n","# fit the tokenizer to Z\n","tokenizer.fit_on_texts(Z)\n","vocab_size = len(tokenizer.word_index) + 1\n","print(\"Vocab size:\", vocab_size)\n","\n","# map the words to integers\n","Z_seq = tokenizer.texts_to_sequences(Z)\n","print(Z_seq)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Vocab size: 6\n","[[3, 1, 4, 5, 2], [3, 1, 2], [2, 1, 4]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JkAO3u4pNrX-","colab_type":"text"},"source":["Then, we want to pad all sequences to the same length. This means all sequences are the same size, and sequences that are short end in zeros. For our toy dataset `Z`, we choose a `maxlen` of 5. "]},{"cell_type":"code","metadata":{"id":"pNefOARgN0aS","colab_type":"code","outputId":"b7d1d2e9-456d-4757-e8ad-b5455afc81c0","executionInfo":{"status":"ok","timestamp":1565967575650,"user_tz":420,"elapsed":1595621,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["Z_pad = pad_sequences(Z_seq, maxlen=5, padding='post')\n","print(Z_pad)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[[3 1 4 5 2]\n"," [3 1 2 0 0]\n"," [2 1 4 0 0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i_mWJ5h_ON4k","colab_type":"text"},"source":["Finish the following function so that it uses a `Tokenizer` fit on `X_train` to convert `X_train`, `X_val`, and `X_test` to padded integer sequences. We choose a maximum length of 100 because as we saw during our data exploration stage, most messages are under 100 tokens long. "]},{"cell_type":"code","metadata":{"id":"7k5jmbBMJALu","colab_type":"code","colab":{}},"source":["def preprocess_data(X_train, X_val, X_test): \n","  '''\n","  @inputs\n","    - X_train, X_val, X_test: Numpy arrays of messages (strings)\n","  @outputs\n","    - X_train_pad, X_val_pad, X_test_pad: Numpy matrices of integers\n","    \n","  '''\n","  max_length = 100\n","  ### YOUR CODE BEGINS HERE ###\n","  # 1. Fit a Tokenizer on X_train\n","  tokenizer = Tokenizer()\n","  tokenizer.fit_on_texts(X_train)\n","  \n","  # 2. Map the words in X_train, X_val, and X_test to integers\n","  X_train_seq = tokenizer.texts_to_sequences(X_train)\n","  X_val_seq = tokenizer.texts_to_sequences(X_val)\n","  X_test_seq = tokenizer.texts_to_sequences(X_test)\n","  \n","  # 3. Pad documents to max length\n","  X_train_pad = pad_sequences(X_train_seq, maxlen=max_length, padding='post')\n","  X_val_pad = pad_sequences(X_val_seq, maxlen=max_length, padding='post')\n","  X_test_pad = pad_sequences(X_test_seq, maxlen=max_length, padding='post')\n","  \n","  ### YOUR CODE ENDS HERE ###\n","  return X_train_pad, X_val_pad, X_test_pad, tokenizer\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XmwZFYVvMlnv","colab_type":"text"},"source":["### Simple Neural Network\n","\n","Our first neural network model will take in an input, pass it through the weights of an embedding layer, flatten it, send it through the weights of a hidden layer of size 5, and then send it through the weights of an output layer of size 1. The embedding layer has size 100 and is randomly initialized. We use a ReLU activation function for the hidden layer, and sigmoid activation function for the output layer. \n","\n","A dense layer is fully connected layer, so if we diagrammed it out, there are arrows from all the nodes in the previous layer to the next layer. \n","\n","![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/320px-Colored_neural_network.svg.png?1565325022586)\n","\n","Here are the building blocks to know about: \n","- `Embedding()`, which has parameters `vocab_size`, `embed_size`, and `input_length`. In our case, we should set `input_length=max_length`. \n","- `Flatten()`\n","- `Dense()`, whose first parameter is 5 and `activation='relu'`.\n","- `Dense()`, whose first parameter is 1 and `activation='sigmoid'`. \n","\n","You can use `model.add()` to add each of these layers to your model. For example, `model.add(Flatten())`.\n","\n","A [diagram](https://drive.google.com/file/d/1yAoMn3OppN7sW3CZDziaIrFaVuo09eto/view?usp=sharing) of our model is below. \n","\n","![alt text](https://i.imgur.com/uAvKDS0.png)"]},{"cell_type":"code","metadata":{"id":"3gFFSfOwEdlt","colab_type":"code","outputId":"abc6032a-377d-4070-cb0c-c789155f1ff6","executionInfo":{"status":"ok","timestamp":1565967688453,"user_tz":420,"elapsed":1708415,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["np.random.seed(42)\n","random.seed(42)\n","tf.set_random_seed(1234)\n","\n","def simple_nn(vocab_size, embed_size, max_length): \n","  model = Sequential()\n","  ### YOUR CODE BEGINS HERE ###\n","  model.add(Embedding(vocab_size, embed_size, input_length=max_length))\n","  model.add(Flatten())\n","  model.add(Dense(5, activation=\"relu\"))\n","  model.add(Dense(1, activation=\"sigmoid\"))\n","  ### YOUR CODE ENDS HERE ###\n","  model.compile(optimizer='adam', loss='binary_crossentropy', \n","                metrics=['acc'])\n","  print(model.summary())\n","  return model\n","\n","# get data\n","X_train, y_train = get_data(path + 'disaster_training.csv')\n","X_val, y_val = get_data(path + 'disaster_validation.csv')\n","X_test, y_test = get_data(path + 'disaster_test.csv')\n","\n","# preprocess data (words --> integers)\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train, X_val, X_test)\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","# create and train the simple neural network model\n","model2 = simple_nn(vocab_size, 100, X_train_pad.shape[1])\n","model2.fit(X_train_pad, y_train, epochs=30, verbose=1)\n","\n","# evaluate the model predictions\n","y_train_pred = model2.predict(X_train_pad)\n","y_train_pred = (y_train_pred > 0.5).astype(int).flatten()\n","print('Training Accuracy: %f' % (accuracy_score(y_train, y_train_pred)))\n","print('Training F1: %f' % (f1_score(y_train, y_train_pred)))\n","y_val_pred = model2.predict(X_val_pad)\n","y_val_pred = (y_val_pred > 0.5).astype(int).flatten()\n","print('Validation Accuracy: %f' % (accuracy_score(y_val, y_val_pred)))\n","print('Validation F1: %f' % (f1_score(y_val, y_val_pred)))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["W0816 14:59:37.290610 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0816 14:59:37.342186 139953364948864 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","W0816 14:59:37.367655 139953364948864 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, 100, 100)          3214600   \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 10000)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 5)                 50005     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 6         \n","=================================================================\n","Total params: 3,264,611\n","Trainable params: 3,264,611\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/30\n","21046/21046 [==============================] - 6s 294us/step - loss: 0.6458 - acc: 0.6601\n","Epoch 2/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.4813 - acc: 0.8156\n","Epoch 3/30\n","21046/21046 [==============================] - 4s 172us/step - loss: 0.2928 - acc: 0.9178\n","Epoch 4/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1864 - acc: 0.9569\n","Epoch 5/30\n","21046/21046 [==============================] - 3s 166us/step - loss: 0.1390 - acc: 0.9693\n","Epoch 6/30\n","21046/21046 [==============================] - 3s 165us/step - loss: 0.1134 - acc: 0.9759\n","Epoch 7/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.0979 - acc: 0.9789\n","Epoch 8/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0900 - acc: 0.9807\n","Epoch 9/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.0826 - acc: 0.9821\n","Epoch 10/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.0781 - acc: 0.9831\n","Epoch 11/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.0766 - acc: 0.9832\n","Epoch 12/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0740 - acc: 0.9838\n","Epoch 13/30\n","21046/21046 [==============================] - 4s 171us/step - loss: 0.0728 - acc: 0.9845\n","Epoch 14/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0715 - acc: 0.9845\n","Epoch 15/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0684 - acc: 0.9853\n","Epoch 16/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.0664 - acc: 0.9857\n","Epoch 17/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0639 - acc: 0.9866\n","Epoch 18/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.0628 - acc: 0.9870\n","Epoch 19/30\n","21046/21046 [==============================] - 3s 166us/step - loss: 0.0616 - acc: 0.9872\n","Epoch 20/30\n","21046/21046 [==============================] - 3s 164us/step - loss: 0.0602 - acc: 0.9873\n","Epoch 21/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0589 - acc: 0.9878\n","Epoch 22/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.0590 - acc: 0.9877\n","Epoch 23/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.0576 - acc: 0.9883\n","Epoch 24/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0560 - acc: 0.9885\n","Epoch 25/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.0551 - acc: 0.9889\n","Epoch 26/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0554 - acc: 0.9886\n","Epoch 27/30\n","21046/21046 [==============================] - 3s 166us/step - loss: 0.0552 - acc: 0.9888\n","Epoch 28/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.0550 - acc: 0.9888\n","Epoch 29/30\n","21046/21046 [==============================] - 4s 166us/step - loss: 0.0557 - acc: 0.9886\n","Epoch 30/30\n","21046/21046 [==============================] - 3s 165us/step - loss: 0.0560 - acc: 0.9887\n","Training Accuracy: 0.989309\n","Training F1: 0.986880\n","Validation Accuracy: 0.716673\n","Validation F1: 0.625193\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bTI9KONKR39q","colab_type":"text"},"source":["We didn't do too bad! It seems like we're **overfitting** a lot to our training data set, though. \n","\n","**Q**: What is overfitting? (Hint: see the plot below.)\n","\n","![alt text](https://upload.wikimedia.org/wikipedia/commons/6/68/Overfitted_Data.png)\n","\n","Our neural network does have a lot of trainable weights, which suggests our model is may be too complex for the number of examples we have. "]},{"cell_type":"markdown","metadata":{"id":"lgrIdo0KMorP","colab_type":"text"},"source":["### Simple NN w/ GloVe\n","\n","We saw that in our previous model, our embeddings for each word were randomly initialized (as a layer of the neural network) and trained along with the rest of the model. \n","\n","Instead of starting with random embeddings and having to learn them, we can instead start with word embeddings that have already been pretrained on some other large corpus of data. Such embeddings are used all the time in NLP.\n","\n","For the embeddings in the model below, we will use 100-dimensional GloVe vectors that have already been trained on Wikipedia and news data. "]},{"cell_type":"code","metadata":{"id":"bGLtamSLimsN","colab_type":"code","colab":{}},"source":["def get_embeddings(): \n","  embeddings = {}\n","  with open('/content/drive/My Drive/Berkeley AI4ALL/glove.twitter.27B.100d.txt', \n","            'r') as glovefile: \n","    for line in glovefile:\n","      values = line.split(' ')\n","      word = values[0]\n","      values = np.asarray(values[1:], dtype='float32')\n","      embeddings[word] = values\n","  return embeddings"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vncPHCx2uGXS","colab_type":"code","outputId":"e0d88f2b-3bf9-487c-e015-ab6c0f080ac0","executionInfo":{"status":"ok","timestamp":1565967725856,"user_tz":420,"elapsed":1745808,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":306}},"source":["embeddings = get_embeddings()\n","print(embeddings['cat'])"],"execution_count":28,"outputs":[{"output_type":"stream","text":["[ 0.38446   -0.45507    0.45351    0.4301    -0.050908  -0.26414\n","  0.43253   -0.3166     0.32214    0.0064333 -0.47066    0.95335\n"," -3.2063     0.010913  -0.27565    1.1732     0.52033   -0.045973\n","  0.094254  -0.53846    0.0035668  0.11934   -0.17815   -0.58093\n","  0.65081   -0.48746   -0.50961    0.42771   -0.30638    0.32385\n","  0.33687   -0.1717    -0.39104   -0.19038    0.37016   -0.50396\n","  0.041969  -0.20517    0.3223     0.41217   -0.42191   -0.26359\n"," -0.1773    -0.35658    0.52145    0.57282    0.60204    0.74369\n","  0.33377   -0.45041    0.015978  -0.12575    0.29786   -0.77635\n","  0.23759    0.63821    0.63726    1.0079     0.13714   -0.031928\n"," -0.21299    0.52348    0.67934   -0.1427    -0.64236   -0.47996\n"," -0.87915    0.17501    0.64517    0.3778     0.53493   -0.29723\n"," -0.25206   -0.757      0.33647    0.053759  -0.8084     0.22205\n","  0.10799   -0.68982    1.5073     0.96641   -0.51839    0.32803\n","  0.11878   -0.72009    0.23227    0.098733  -0.096396   0.40295\n"," -0.003925  -0.10405   -0.15234    0.17573    0.29694    0.14938\n","  0.11754    0.15699   -0.34272    0.2435   ]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HbhnqIrLiH_X","colab_type":"text"},"source":["Each vector encodes the meaning of a word. The values in each vector are learned based on the context that surrounds a word each time it occurred in the training corpus. \n","\n","For example, we can estimate how similar two words are in meaning by computing the cosine distance between their corresponding embedding vectors: "]},{"cell_type":"code","metadata":{"id":"DFQk1ySyitUh","colab_type":"code","outputId":"e252a579-506a-4926-af40-b5d94d1b81a6","executionInfo":{"status":"ok","timestamp":1565967725858,"user_tz":420,"elapsed":1745804,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# 'cat' and 'dog' have a smaller distance and are closer together\n","# in meaning than 'cat' and 'chair'\n","# Feel free to compute cosine distance for other pairs of words \n","print(cosine(embeddings['cat'], embeddings['dog']))\n","print(cosine(embeddings['cat'], embeddings['chair']))"],"execution_count":29,"outputs":[{"output_type":"stream","text":["0.1247909665107727\n","0.511318564414978\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VFxfhio_kGyS","colab_type":"text"},"source":["[Here](http://projector.tensorflow.org/) is a cool interactive visualization of another type of word embedding, called word2vec, which works in a similar manner as GloVe. \n","\n","We can compute the nearest neighbors of different GloVe words as well, to see that closer words are more closely related."]},{"cell_type":"code","metadata":{"id":"TeAleLQBkc-H","colab_type":"code","outputId":"7a16f157-5bcc-4957-921a-706d68f25366","executionInfo":{"status":"ok","timestamp":1565967729629,"user_tz":420,"elapsed":1749569,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Feel free to try other words as well \n","word = 'girl'\n","\n","# find the word\n","vocab = sorted(embeddings.keys())\n","idx = vocab.index(word)\n","\n","# get the embeddings of every other word\n","m = []\n","for word in vocab: \n","  m.append(embeddings[word])\n","m = np.array(m)\n","\n","# compute similarity between embeddings of the word and all other words\n","sim_m = cosine_similarity(m, [m[idx]])\n","\n","# show the top 10 closest words to the given word\n","ranking = np.argsort(sim_m, axis=0)\n","for j in range(2, 12): # skip 1 because it's itself\n","  print(vocab[ranking[-j][0]])"],"execution_count":30,"outputs":[{"output_type":"stream","text":["boy\n","girls\n","she\n","friend\n","guy\n","chick\n","like\n","sister\n","boyfriend\n","bitch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ck6habLclChG","colab_type":"text"},"source":["We saw above that words with similar semantic relationships to each other are mapped into the embedding space in similar ways. \n","\n","<img src=\"https://nlp.stanford.edu/projects/glove/images/comparative_superlative.jpg\" alt=\"Glove Word Analogies\" width=\"600\"/>\n","\n","Word embeddings can also be used to compute analogies using arithmetic. Our embeddings are only 100-dimensional so they don't perform too great on some classic analogies (e.g. king - man + queen yields royal instead of woman), but they still do pretty well on cities & capitals, as we will see next."]},{"cell_type":"code","metadata":{"id":"4ISpaHcvlLy-","colab_type":"code","outputId":"780413b6-df32-4392-98b8-fb00912e0822","executionInfo":{"status":"ok","timestamp":1565967733153,"user_tz":420,"elapsed":1753087,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["analogies = [('china', 'beijing', 'paris'), \n","             ('germany', 'berlin', 'london'), \n","             ('stronger', 'strongest', 'softer'), \n","             ('king', 'man', 'queen')\n","            ]\n","for analogy in analogies: \n","  result = embeddings[analogy[0]] - embeddings[analogy[1]] + embeddings[analogy[2]]\n","  \n","  # calculate similarity between our 'result' and\n","  # m, which has the embeddings of all words in the vocab\n","  sim_m = cosine_similarity(m, [result])\n","  \n","  # show the closest word to our 'result' that wasn't in the original list\n","  ranking = np.argsort(sim_m, axis=0)\n","  for j in range(1, 5): # skip 1 because it's itself\n","    w = vocab[ranking[-j][0]]\n","    if w not in analogy: \n","      print(analogy, w)\n","      break"],"execution_count":31,"outputs":[{"output_type":"stream","text":["('china', 'beijing', 'paris') france\n","('germany', 'berlin', 'london') england\n","('stronger', 'strongest', 'softer') smoother\n","('king', 'man', 'queen') royal\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C_SHaY5DMqz6","colab_type":"text"},"source":["Now, we'll modify the `Embedding` layer of our simple neural network to include GloVe vectors. This layer needs to take in an `embedding_matrix` so it knows how to look up the GloVe vectors for each word. "]},{"cell_type":"code","metadata":{"id":"kcO5YAKuqHAO","colab_type":"code","colab":{}},"source":["def get_embedding_matrix(embeddings, vocab_size, embed_size, tokenizer): \n","  '''\n","  Defines a matrix where each row corresponds\n","  to a word's GloVe vector. \n","  The rows are in the same order as the word->integer\n","  mapping in our tokenizer. ]\n","  @inputs\n","  - embeddings: a dictionary from a word (string) to a vector\n","  - vocab_size: int\n","  - embed_size: int, same size as # of elements in GloVe vector\n","  - tokenizer: Tokenizer from preprocess_data()\n","  '''\n","  \n","  embedding_matrix = np.zeros((vocab_size, embed_size))\n","  # for each word from the tokenizer, get its corresponding embedding\n","  for word, i in tokenizer.word_index.items():\n","    embedding_vector = embeddings.get(word)\n","    if embedding_vector is not None:\n","      embedding_matrix[i] = embedding_vector\n","      \n","  # return embeddings of all words from the tokenizer\n","  return embedding_matrix"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-q7f6oGw8E5k","colab_type":"text"},"source":["Now, we want to write code in `simple_glove_nn()` that is the same as `simple_nn()` except the `Embedding` layer will now have more parameters. To the embedding layer, you'll want to add the parameters `weights=[embedding_matrix]` and `trainable=True`. This will use the embedding matrix to map our words into vectors, and still allow those weights to be further trained on the given data. \n","\n","Note that this differs from our first simple neural network because the embedding weights are now starting from a pretrained embedding, rather than starting from random weights."]},{"cell_type":"code","metadata":{"id":"EAmIlxxvhS0g","colab_type":"code","outputId":"47c20ecc-b364-46ce-903d-2a4841c091ce","executionInfo":{"status":"ok","timestamp":1565967876628,"user_tz":420,"elapsed":1896554,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["np.random.seed(42)\n","random.seed(42)\n","tf.set_random_seed(1234)\n","\n","def simple_glove_nn(vocab_size, embed_size, max_length, embedding_matrix): \n","  model = Sequential()\n","  ### YOUR CODE BEGINS HERE ###\n","  model.add(Embedding(vocab_size, embed_size, input_length=max_length, weights=[embedding_matrix], trainable=True))\n","  model.add(Flatten())\n","  model.add(Dense(5, activation=\"relu\"))\n","  model.add(Dense(1, activation=\"sigmoid\"))\n","  ### YOUR CODE ENDS HERE ###\n","  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","  print(model.summary())\n","  return model \n","\n","X_train, y_train = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_training.csv')\n","X_val, y_val = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_validation.csv')\n","X_test, y_test = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_test.csv')\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train, \n","                                                                 X_val, X_test)\n","vocab_size = len(tokenizer.word_index) + 1\n","embed_size = 100\n","embeddings = get_embeddings()\n","embedding_matrix = get_embedding_matrix(embeddings, vocab_size, \n","                                        embed_size, tokenizer)\n","model3 = simple_glove_nn(vocab_size, embed_size, X_train_pad.shape[1], embedding_matrix)\n","model3.fit(X_train_pad, y_train, epochs=30, verbose=1)\n","\n","y_train_pred = model3.predict(X_train_pad)\n","y_train_pred = (y_train_pred > 0.5).astype(int).flatten()\n","print('Training Accuracy: %f' % (accuracy_score(y_train, y_train_pred)))\n","print('Training F1: %f' % (f1_score(y_train, y_train_pred)))\n","y_val_pred = model3.predict(X_val_pad)\n","y_val_pred = (y_val_pred > 0.5).astype(int).flatten()\n","print('Validation Accuracy: %f' % (accuracy_score(y_val, y_val_pred)))\n","print('Validation F1: %f' % (f1_score(y_val, y_val_pred)))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 100, 100)          3214600   \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 10000)             0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 5)                 50005     \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1)                 6         \n","=================================================================\n","Total params: 3,264,611\n","Trainable params: 3,264,611\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Epoch 1/30\n","21046/21046 [==============================] - 4s 186us/step - loss: 0.6377 - acc: 0.6807\n","Epoch 2/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.4970 - acc: 0.8050\n","Epoch 3/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.3751 - acc: 0.8732\n","Epoch 4/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.2714 - acc: 0.9217\n","Epoch 5/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.2034 - acc: 0.9467\n","Epoch 6/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1666 - acc: 0.9576\n","Epoch 7/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1466 - acc: 0.9632\n","Epoch 8/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1351 - acc: 0.9658\n","Epoch 9/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1262 - acc: 0.9684\n","Epoch 10/30\n","21046/21046 [==============================] - 4s 171us/step - loss: 0.1214 - acc: 0.9701\n","Epoch 11/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1192 - acc: 0.9707\n","Epoch 12/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.1172 - acc: 0.9711\n","Epoch 13/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.1161 - acc: 0.9713\n","Epoch 14/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.1146 - acc: 0.9717\n","Epoch 15/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1163 - acc: 0.9713\n","Epoch 16/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1128 - acc: 0.9723\n","Epoch 17/30\n","21046/21046 [==============================] - 4s 171us/step - loss: 0.1113 - acc: 0.9731\n","Epoch 18/30\n","21046/21046 [==============================] - 4s 173us/step - loss: 0.1109 - acc: 0.9731\n","Epoch 19/30\n","21046/21046 [==============================] - 4s 173us/step - loss: 0.1102 - acc: 0.9731\n","Epoch 20/30\n","21046/21046 [==============================] - 4s 171us/step - loss: 0.1103 - acc: 0.9732\n","Epoch 21/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1100 - acc: 0.9735\n","Epoch 22/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1108 - acc: 0.9731\n","Epoch 23/30\n","21046/21046 [==============================] - 4s 167us/step - loss: 0.1088 - acc: 0.9739\n","Epoch 24/30\n","21046/21046 [==============================] - 4s 169us/step - loss: 0.1087 - acc: 0.9738\n","Epoch 25/30\n","21046/21046 [==============================] - 4s 166us/step - loss: 0.1083 - acc: 0.9737\n","Epoch 26/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1080 - acc: 0.9740\n","Epoch 27/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1074 - acc: 0.9741\n","Epoch 28/30\n","21046/21046 [==============================] - 4s 170us/step - loss: 0.1083 - acc: 0.9737\n","Epoch 29/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1078 - acc: 0.9741\n","Epoch 30/30\n","21046/21046 [==============================] - 4s 168us/step - loss: 0.1073 - acc: 0.9743\n","Training Accuracy: 0.974437\n","Training F1: 0.968041\n","Validation Accuracy: 0.722892\n","Validation F1: 0.618104\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ntCoh6CLC5TS","colab_type":"text"},"source":["Surprisingly, we don't see too much of an improvement, even by using pre-trained word embeddings. Still, pre-trained word embeddings are commonly used in NLP, and so we'd like them to be an option for you to later include in your custom neural network (near the end of this notebook). "]},{"cell_type":"markdown","metadata":{"id":"WADcXWMpMswU","colab_type":"text"},"source":["### LSTM w/ GloVe\n","\n","Now we will use a more complex model. \n","\n","A recurrent neural network (RNN) looks like the following when unrolled: \n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/800px-Recurrent_neural_network_unfold.svg.png\" alt=\"RNN\" width=\"600\"/> \n","\n","Here, $x_{t}$ is a token in our dataset, and $h_{t}$ are hidden states, and $o_{t}$ are outputs. For our problem, instead of an output at every time step (at every word), we will have a single output at the last RNN layer (after seeing every word). \n","\n","Our hidden cells are called LSTMs (long short-term memory). \n","\n","This is what an LSTM looks like (think of it as one of the blue $h_t$ rectangles in the illustration above). \n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/3b/The_LSTM_cell.png\" alt=\"LSTM Cell\" width=\"300\"/>\n","\n","You don't have to worry about understanding all of the arrows and components, but the main idea is that there are multiple calculations involved in an LSTM. These calculations correspond to things like forgetting, manipulating, or sending forward certain parts of the incoming information. \n","\n","[This](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) is a really good blog post about LSTMs if you want to do further reading. \n","\n","In this section, you will put together a neural model that we designed to help prep you to create your own model in the next section. Instead of using Keras's standard `LSTM` layer, we will use `CuDNNLSTM` which is an implementation that runs faster on a GPU. \n","\n","We also introduce a new concept called **regularization**, which is a technique for reducing overfitting. We'll specifically use dropout. \n","\n","With dropout, randomly selected inputs are ignored. This makes our model more flexible, and it's sort of like training multiple \"thinner\" neural networks at the same time. Keras makes it so that dropout only occurs during training, not during predicting. \n","\n","A [diagram](https://drive.google.com/file/d/1YJoZLbYqfKaMDPf6peRf58BizIueBSU3/view?usp=sharing) of our model is below. (Note that our sequences are actually 100 tokens long, but this toy diagram pretends it's 4 tokens long.)\n","\n","<img src=\"https://i.imgur.com/l1HOV5r.png\" alt=\"Stacked LSTM with Embeddings\" width=\"400\"/>\n","\n","This neural network will have the following components: \n","* `Embedding` layer the same as our simple NN w/ GloVe, except `trainable=False`. This means the embedding layer doesn't change when our model learns. We found that this makes the network perform better. \n","* `CuDNNLSTM` layer of size 10, and `return_sequences=True`. We want to return sequences so we can stack another LSTM on top of this one. \n","* `CuDNNLSTM` layer of size 50, and `return_sequences=True`.\n","* `Dropout` with `rate=0.2`. We are essentially setting 20% of inputs to zero. \n","* `CuDNNLSTM` layer of size 20. \n","* `Dense` layer of size 1 with a sigmoid activation function. \n","\n","While this model is training, you can look at the Fun Resources section at the bottom of this notebook. This model should take about 20 minutes to train. You can also start brainstorming your custom model. "]},{"cell_type":"code","metadata":{"id":"vanMNYmp3mSm","colab_type":"code","outputId":"d792828c-8de9-4562-dd9e-02b7eb1644d6","executionInfo":{"status":"error","timestamp":1565968187090,"user_tz":420,"elapsed":2207008,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["np.random.seed(42)\n","random.seed(42)\n","tf.set_random_seed(1234)\n","\n","def lstm_glove(vocab_size, embed_size, max_length, embedding_matrix): \n","  model = Sequential()\n","  ### YOUR CODE BEGINS HERE ###\n","  model.add(Embedding(vocab_size, embed_size, input_length=max_length, weights=[embedding_matrix], trainable=False))\n","  model.add(CuDNNLSTM(10, return_sequences=True))\n","  model.add(CuDNNLSTM(50, return_sequences=True))\n","  model.add(Dropout(rate=0.2))\n","  model.add(CuDNNLSTM(20))\n","  model.add(Dense(1, activation = \"sigmoid\"))\n","  ### YOUR CODE ENDS HERE ###\n","  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","  print(model.summary())\n","  return model\n","\n","X_train, y_train = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_training.csv')\n","X_val, y_val = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_validation.csv')\n","X_test, y_test = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_test.csv')\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train,X_val, X_test)\n","vocab_size = len(tokenizer.word_index) + 1\n","embed_size = 100\n","embeddings = get_embeddings()\n","embedding_matrix = get_embedding_matrix(embeddings, vocab_size, embed_size, tokenizer)\n","model4 = lstm_glove(vocab_size, embed_size, X_train_pad.shape[1], embedding_matrix)\n","model4.fit(X_train_pad, y_train, epochs=30, verbose=1)\n","\n","y_train_pred = model4.predict(X_train_pad)\n","y_train_pred = (y_train_pred > 0.5).astype(int).flatten()\n","print('Training Accuracy: %f' % (accuracy_score(y_train, y_train_pred)))\n","print('Training F1: %f' % (f1_score(y_train, y_train_pred)))\n","y_val_pred = model4.predict(X_val_pad)\n","y_val_pred = (y_val_pred > 0.5).astype(int).flatten()\n","print('Validation Accuracy: %f' % (accuracy_score(y_val, y_val_pred)))\n","print('Validation F1: %f' % (f1_score(y_val, y_val_pred)))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["W0816 15:05:13.306663 139953364948864 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stderr"},{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_3 (Embedding)      (None, 100, 100)          3214600   \n","_________________________________________________________________\n","cu_dnnlstm_1 (CuDNNLSTM)     (None, 100, 10)           4480      \n","_________________________________________________________________\n","cu_dnnlstm_2 (CuDNNLSTM)     (None, 100, 50)           12400     \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 100, 50)           0         \n","_________________________________________________________________\n","cu_dnnlstm_3 (CuDNNLSTM)     (None, 20)                5760      \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1)                 21        \n","=================================================================\n","Total params: 3,237,261\n","Trainable params: 22,661\n","Non-trainable params: 3,214,600\n","_________________________________________________________________\n","None\n","Epoch 1/30\n","21046/21046 [==============================] - 15s 724us/step - loss: 0.6163 - acc: 0.6644\n","Epoch 2/30\n","21046/21046 [==============================] - 12s 584us/step - loss: 0.6463 - acc: 0.6431\n","Epoch 3/30\n","21046/21046 [==============================] - 12s 586us/step - loss: 0.6126 - acc: 0.6834\n","Epoch 4/30\n","21046/21046 [==============================] - 12s 590us/step - loss: 0.6008 - acc: 0.6982\n","Epoch 5/30\n","21046/21046 [==============================] - 12s 582us/step - loss: 0.5732 - acc: 0.7198\n","Epoch 6/30\n","21046/21046 [==============================] - 12s 586us/step - loss: 0.5128 - acc: 0.7542\n","Epoch 7/30\n","21046/21046 [==============================] - 12s 583us/step - loss: 0.4996 - acc: 0.7619\n","Epoch 8/30\n","21046/21046 [==============================] - 12s 585us/step - loss: 0.4869 - acc: 0.7648\n","Epoch 9/30\n","21046/21046 [==============================] - 12s 592us/step - loss: 0.5055 - acc: 0.7583\n","Epoch 10/30\n","21046/21046 [==============================] - 12s 588us/step - loss: 0.4770 - acc: 0.7739\n","Epoch 11/30\n","21046/21046 [==============================] - 12s 587us/step - loss: 0.4728 - acc: 0.7755\n","Epoch 12/30\n","21046/21046 [==============================] - 12s 591us/step - loss: 0.4645 - acc: 0.7807\n","Epoch 13/30\n","21046/21046 [==============================] - 12s 582us/step - loss: 0.4588 - acc: 0.7821\n","Epoch 14/30\n","21046/21046 [==============================] - 12s 587us/step - loss: 0.4536 - acc: 0.7844\n","Epoch 15/30\n","21046/21046 [==============================] - 12s 590us/step - loss: 0.4488 - acc: 0.7873\n","Epoch 16/30\n","21046/21046 [==============================] - 12s 588us/step - loss: 0.4456 - acc: 0.7883\n","Epoch 17/30\n","21046/21046 [==============================] - 12s 584us/step - loss: 0.4400 - acc: 0.7926\n","Epoch 18/30\n","21046/21046 [==============================] - 12s 586us/step - loss: 0.4345 - acc: 0.7958\n","Epoch 19/30\n","21046/21046 [==============================] - 12s 590us/step - loss: 0.4303 - acc: 0.7975\n","Epoch 20/30\n","21046/21046 [==============================] - 12s 577us/step - loss: 0.4252 - acc: 0.7998\n","Epoch 21/30\n","21046/21046 [==============================] - 12s 583us/step - loss: 0.4214 - acc: 0.8014\n","Epoch 22/30\n","16416/21046 [======================>.......] - ETA: 2s - loss: 0.4181 - acc: 0.8018"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-64bee2637512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmodel4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_glove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membed_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_pad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"zuh3r2UmlPl0","colab_type":"text"},"source":["### Your Own NN!\n","\n","Here you'll build your own neural network for our classification task. \n","\n","Recall the different building blocks we've given you in previous models: \n","* The `Embedding` layer, which can include GloVe or be random. If you use GloVe, you can set this to be trainable or not trainable. \n","* `Flatten`, which is used if you want to input your embedding layer or any LSTM sequence layers into a dense layer. \n","* `Dense`, which is just a regular densely-connected neural network layer. We've seen dense layers of size 5 and 1, but you can set this value to whatever you what. Remember to add a dense layer of size 1 with a sigmoid activation function at the end. \n","* `CuDNNLSTM`, which is an LSTM. You can stack these by returning sequences. We've seen examples of LSTMs of size 20 and 50. You can set the dimensionality of the output to whatever you want. \n","\n","Now, note that when we say \"whatever you want,\" you should keep in mind that the larger your model, the longer it will take to train. Also, Colaboratory doesn't have infinite resources, so you may end up crashing the notebook if you try to make it do too much. We recommend playing around with values between 0 and 100 for now. \n","\n","When you modify these hyperparameters such as the size of each layer, you're performing what is known as **hyperparameter tuning**. Make sure you write down the values you get with different versions of your model so you can figure out which set of hyperparameters yields the best model you can come up with. \n","\n","*   If your training accuracy is much higher than your test accuracy, try making your model smaller (e.g. fewer units in each LSTM layer or fewer LSTM layers) or adding dropout regularization.\n","*   If your training accuracy and test accuracy are similar, try making your model bigger. \n","\n","<img src=\"https://miro.medium.com/max/700/1*WyncMcJhXa7yPYebXyRq-Q.png\" alt=\"error and model\" width=\"400\"/> \n","\n","In practice, AI researchers may use random search for finding the best hyperparameters for their models. We won't have time to search over many different sets of hyperparameters, but hopefully trying one or two different models is enough to give you a taste of the process. "]},{"cell_type":"code","metadata":{"id":"xoyGlaTUoX9a","colab_type":"code","colab":{}},"source":["X_train, y_train = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_training.csv')\n","X_val, y_val = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_validation.csv')\n","X_test, y_test = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_test.csv')\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train, \n","                                                                 X_val, X_test)\n","vocab_size = len(tokenizer.word_index) + 1\n","embed_size = 100\n","embeddings = get_embeddings()\n","embedding_matrix = get_embedding_matrix(embeddings, vocab_size, \n","                                        embed_size, tokenizer)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PAwFmv5K1YZ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"1a8bfa20-83cf-4ce6-cf56-aab7eddef4f5","executionInfo":{"status":"ok","timestamp":1565982565308,"user_tz":420,"elapsed":555,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}}},"source":["vocab_size\n"],"execution_count":55,"outputs":[{"output_type":"execute_result","data":{"text/plain":["32146"]},"metadata":{"tags":[]},"execution_count":55}]},{"cell_type":"code","metadata":{"id":"LdxE_poAQhDG","colab_type":"code","outputId":"3f8d72f9-2596-432d-cd5c-e33a564e69dc","executionInfo":{"status":"error","timestamp":1566183818380,"user_tz":420,"elapsed":368,"user":{"displayName":"Aroshi Ghosh","photoUrl":"https://lh4.googleusercontent.com/-XqVxXPW1WfU/AAAAAAAAAAI/AAAAAAAADyc/UdfOq7iDyqg/s64/photo.jpg","userId":"15064503538591477262"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["reg = 0.5e-6\n","np.random.seed(42)\n","random.seed(42)\n","tf.set_random_seed(1234)\n","\n","def my_custom_model(vocab_size, embed_size, max_length, embedding_matrix): \n","  model = Sequential()\n","  ### YOUR CODE BEGINS HERE ###\n","  model.add(Embedding(vocab_size, embed_size, input_length=max_length, weights=[embedding_matrix], trainable=False))\n","  model.add(CuDNNLSTM(90, return_sequences=True, kernel_regularizer=l2(reg), recurrent_regularizer=l2(reg), bias_regularizer=l2(reg)))\n","  model.add(BatchNormalization())\n","  model.add(CuDNNLSTM(90, return_sequences=True, kernel_regularizer=l2(reg), recurrent_regularizer=l2(reg), bias_regularizer=l2(reg)))\n","  model.add(Dropout(rate=0.5))\n","  model.add(CuDNNLSTM(90, return_sequences=True, kernel_regularizer=l2(reg), recurrent_regularizer=l2(reg), bias_regularizer=l2(reg)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(rate=0.5))\n","  model.add(CuDNNLSTM(90, return_sequences=True, kernel_regularizer=l2(reg), recurrent_regularizer=l2(reg), bias_regularizer=l2(reg)))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(rate=0.5))\n","  model.add(CuDNNLSTM(90, kernel_regularizer=l2(reg), recurrent_regularizer=l2(reg), bias_regularizer=l2(reg)))\n","  model.add(BatchNormalization())\n","  model.add(Dense(10, activation=\"relu\"))\n","  model.add(Dense(1, activation=\"sigmoid\"))\n","  ### YOUR CODE ENDS HERE ###\n","  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","  print(model.summary())\n","  return model\n","\n","\n","model5 = my_custom_model(vocab_size, embed_size, X_train_pad.shape[1], \n","                   embedding_matrix)\n","model5.fit(X_train_pad, y_train, epochs=30, verbose=1, validation_data=(X_val_pad, y_val), batch_size=16)\n","\n","y_train_pred = model5.predict(X_train_pad)\n","y_train_pred = (y_train_pred > 0.5).astype(int).flatten()\n","print('Training Accuracy: %f' % (accuracy_score(y_train, y_train_pred)))\n","print('Training F1: %f' % (f1_score(y_train, y_train_pred)))\n","y_val_pred = model5.predict(X_val_pad)\n","y_val_pred = (y_val_pred > 0.5).astype(int).flatten()\n","print('Validation Accuracy: %f' % (accuracy_score(y_val, y_val_pred)))\n","print('Validation F1: %f' % (f1_score(y_val, y_val_pred)))"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-6cee4e7fb065>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"code","metadata":{"id":"MYp6ZTaO9PXg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"24ZYtC5kWhip","colab_type":"text"},"source":["## Results & Analysis"]},{"cell_type":"markdown","metadata":{"id":"8g2YjPOvQoGF","colab_type":"text"},"source":["Now, time to analyze the results we got for the five models we created. \n","\n","First, we can compare how we did on the training and validation sets for each. "]},{"cell_type":"code","metadata":{"id":"ne3sbosAlpu_","colab_type":"code","colab":{}},"source":["def autolabel(rects, ax):\n","  \"\"\"\n","  Attach a text label above each bar in *rects*, displaying its height.\n","  Copied from the matplotlib tutorial for \"Grouped bar chart with labels\".\n","  \"\"\"\n","  for rect in rects:\n","    height = rect.get_height()\n","    ax.annotate('{}'.format(height),\n","                xy=(rect.get_x() + rect.get_width() / 2, height),\n","                xytext=(0, 3),  # 3 points vertical offset\n","                textcoords=\"offset points\",\n","                ha='center', va='bottom')\n","      \n","def plot_comparison(training_scores, validation_scores, labels, ylabel): \n","  x = np.arange(len(labels))  \n","  width = 0.35  \n","  fig, ax = plt.subplots()\n","  rects1 = ax.bar(x - width/2, training_scores, width, label='Training')\n","  rects2 = ax.bar(x + width/2, validation_scores, width, label='Validation')\n","  ax.set_ylabel(ylabel, size=15)\n","  ax.set_xticks(x)\n","  ax.set_xticklabels(labels, rotation=30)\n","  ax.spines['right'].set_visible(False)\n","  ax.spines['top'].set_visible(False)\n","  ax.legend()\n","  autolabel(rects1, ax)\n","  autolabel(rects2, ax)\n","  fig.tight_layout()\n","  plt.show()\n","\n","labels = ['baseline', 'logistic regression', 'simple NN', 'simple NN w/GloVe', \n","          'LSTM w/ GloVe', 'our model']\n","### YOUR CODE BEGINS HERE ###\n","# replace these dummy values with your scores in the same order as labels\n","training_F1 = [1, 2, 3, 4, 5, 6]\n","training_acc = [6, 7, 8, 9, 10, 11]\n","validation_F1 = [2, 3, 4, 5, 6, 7]\n","validation_acc = [6, 5, 4, 3, 2, 1]\n","### YOUR CODE ENDS HERE ###\n","\n","plot_comparison(training_F1, validation_F1, labels, 'F1 Score')\n","plot_comparison(training_acc, validation_acc, labels, 'Accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IGmR_02JQ3Vv","colab_type":"text"},"source":["In the \"real world\", AI researchers compete for the best test set score on leaderboards for tasks such as question answering and textual entailment. These researchers develop a model on the training and validation sets, which are released publicly. Then, they submit their model to the leaderboard, which runs their model on a hidden test set and ranks how well they perform against others. Here's some examples: [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/) and [GLUE](https://gluebenchmark.com/leaderboard).\n","\n","We'll pretend we're submitting a model to a leaderboard of some sort. We'll run our best model, as determined by validation accuracy, on the test set. \n","\n","The following code assumes that our pre-designed LSTM w/ GloVe is the best model. However, it could be that your own custom model performs better! If that is the case, you can just swap out `model4` with your `model5`. "]},{"cell_type":"code","metadata":{"id":"xUKy2vF21HA6","colab_type":"code","colab":{}},"source":["# run our best model on the test set \n","X_train, y_train = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_training.csv')\n","X_val, y_val = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_validation.csv')\n","X_test, y_test = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_test.csv')\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train, \n","                                                                 X_val, X_test)\n","### YOUR CODE BEGINS HERE ###\n","# predict on X_test_pad to get y_test_pad\n","### YOUR CODE ENDS HERE ###\n","y_test_pred = (y_test_pred > 0.5).astype(int).flatten()\n","print('Validation Accuracy: %f' % (accuracy_score(y_test, y_test_pred)))\n","print('Validation F1: %f' % (f1_score(y_test, y_test_pred)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ol4Le4_Q-Bc","colab_type":"text"},"source":["To get an idea of what a neural network has learned, we can visualize hidden layer features. To do this, we cut off our best model right before the Dense layer and predict on the test set to get hidden features. \n","\n","Since we can't visualize 20 dimensions very well on a computer screen, we reduce the dimensionality of the hidden features to 2 using [t-SNE](https://towardsdatascience.com/an-introduction-to-t-sne-with-python-example-5a3a293108d1). T-SNE attempts to arrange points so that those that are close in high-dimensional space are still close in 2-D, and those that were far are still far. \n","\n","The resulting plot below would show the reduced features colored by their true label. \n","\n","The goal is for a neural network to separate out the messages with different labels to different areas of space. "]},{"cell_type":"code","metadata":{"id":"e1Yp2-YzWiQo","colab_type":"code","colab":{}},"source":["np.random.seed(42)\n","random.seed(42)\n","tf.set_random_seed(1234)\n","\n","def truncate_model(model, vocab_size, embed_size, max_length, embedding_matrix):\n","    model_short = Sequential()\n","    ### YOUR CODE BEGINS HERE ###\n","    # This code should be copied from the code you wrote for \n","    # model4 or model5 except you remove the final Dense layer\n","    ### YOUR CODE ENDS HERE ###\n","    for i, layer in enumerate(model_short.layers):\n","        layer.set_weights(model.layers[i].get_weights())\n","    model_short.compile(optimizer='adam', loss='binary_crossentropy', \n","                        metrics=['acc'])\n","    return model_short\n","\n","# get data and embeddings\n","X_train, y_train = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_training.csv')\n","X_val, y_val = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_validation.csv')\n","X_test, y_test = get_data('/content/drive/My Drive/Berkeley AI4ALL/disaster_test.csv')\n","X_train_pad, X_val_pad, X_test_pad, tokenizer = preprocess_data(X_train, \n","                                                                 X_val, X_test)\n","vocab_size = len(tokenizer.word_index) + 1\n","embed_size = 100\n","embeddings = get_embeddings()\n","embedding_matrix = get_embedding_matrix(embeddings, vocab_size, \n","                                        embed_size, tokenizer)\n","\n","# truncate the model, so we can examine the outputs of an earlier layer (i.e. 'features')\n","### YOUR CODE BEGINS HERE ###\n","# Change model4 to model5 if your model5 performs better\n","model_short = truncate_model(model4, vocab_size, embed_size, \n","                             X_train_pad.shape[1], embedding_matrix)\n","### YOUR CODE ENDS HERE ###\n","features = model_short.predict(X_test_pad)\n","\n","# We'll just visualize a subset of the data\n","# by fitting our 'features' with a lower-dimensional representation \n","# which we can then plot, to look for trends/patterns\n","num_points = 1000\n","tsne = TSNE(n_components=2)\n","tsne_features = tsne.fit_transform(features[:num_points])\n","color_dict = {0: \"green\", 1: \"orange\"}\n","colors = []\n","for label in y_test[:num_points]: \n","  colors.append(color_dict[label])\n","fig, ax = plt.subplots()\n","plt.scatter(tsne_features[:,0], tsne_features[:,1], \n","            c=colors, alpha=0.1)\n","legend_elements = [Line2D([0], [0], marker='o', color='w', \n","                          label='not aid-related',\n","                          markerfacecolor='green', markersize=15), \n","                   Line2D([0], [0], marker='o', color='w', \n","                          label='aid-related',\n","                          markerfacecolor='orange', markersize=15)]\n","ax.legend(handles=legend_elements)\n","plt.xlabel(\"Dimension 1\")\n","plt.ylabel(\"Dimension 2\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FbyIvCBRJP-","colab_type":"text"},"source":["We can also look at what kind of mistakes we made. A confusion matrix displays the number of false positives, false negatives, true negatives, and true positives we got with our model. Go back up to the explanation of F1 for a table representing a confusion matrix. Your code for calculating F1 is very similar to the code for calculating the values in a confusion matrix. "]},{"cell_type":"code","metadata":{"id":"V9f_TyKuRIKd","colab_type":"code","colab":{}},"source":["# confusion matrix\n","def display_confusion_matrix(y_true, y_pred): \n","  '''\n","  A function for calculating F1\n","  Start by computing TP, FP, and FN, \n","  then precision and recall. \n","  @inputs: \n","    - y_pred: numpy array of predicted labels\n","    - y_true: numpy array of actual labels\n","  '''\n","  true_positives = 0\n","  false_positives = 0\n","  false_negatives = 0\n","  true_negatives = 0\n","  ### YOUR CODE BEGINS HERE ###\n","  # calculate each of the matrix values\n","  ### YOUR CODE ENDS HERE ###\n","  conf_mat = np.zeros((2, 2))\n","  conf_mat[0][0] = true_positives\n","  conf_mat[1][1] = true_negatives\n","  conf_mat[0][1] = false_positives\n","  conf_mat[1][0] = false_negatives\n","  sns.heatmap(conf_mat, cmap=\"YlGnBu\", annot=True, \n","              fmt='.1f', yticklabels=[1, 0], xticklabels=[1, 0])\n","  plt.title('Confusion Matrix for Test Set')\n","  plt.ylabel('Predicted Value')\n","  plt.xlabel('Actual Value')\n","  plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PdyXYwS4iXa","colab_type":"code","colab":{}},"source":["display_confusion_matrix(y_test, y_test_pred)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OLT6iwcYlmjt","colab_type":"code","colab":{}},"source":["# examples of errors\n","# feel free to run this cell multiple times to see more examples\n","print(\"true\\tpred\\tmessage\")\n","for idx in random.sample(list(np.where(y_test_pred != y_test)[0]), 10): \n","  print(y_test[idx], '\\t', y_test_pred[idx], '\\t', X_test[idx])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fj8eISJjAXld","colab_type":"text"},"source":["**Q**: What do you think are some reasons why our model made these mistakes?  "]},{"cell_type":"markdown","metadata":{"id":"1H7t_4o2HnOp","colab_type":"text"},"source":["## Fun Resources \n","\n","Good job! You've reached the end of this notebook. \n","\n","Here are some fun links for exploring more of NLP/AI.  \n","\n","*  [Talk To Transformer](https://talktotransformer.com/) - Type stuff and a neural network guesses what comes next\n","* [Thing Translator](https://thing-translator.appspot.com/) - Take pictures of objects and translate them in different languages (use this with your phone)\n","* [Allen NLP demos](https://demo.allennlp.org/) - They have a lot of different demos you can try out on the left sidebar \n","* [Talk to Books](https://books.google.com/talktobooks/) - Browse books using everyday language\n","* [Tensorflow Playground](http://playground.tensorflow.org) - Play around with a neural network in your browser\n","* [Quick, Draw](https://quickdraw.withgoogle.com/) - Contribute doodles to a drawing [dataset](https://quickdraw.withgoogle.com/data). \n","\n","Browse the syllabi of NLP classes that college students take! These may be challenging to understand, but it can give you an idea of the possibilities in this field. \n","\n"," * Stanford [CS 124](http://web.stanford.edu/class/cs124/) - From Languages to Information\n","\n","* Berkeley [Info 256](http://people.ischool.berkeley.edu/~dbamman/info256.html) - Applied Natural Language Processing\n","\n","* University of Washington [CSE 517](https://courses.cs.washington.edu/courses/cse517/19wi/) - Natural Language Processing\n","\n"]},{"cell_type":"code","metadata":{"id":"yQpLU8rXSCC0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}